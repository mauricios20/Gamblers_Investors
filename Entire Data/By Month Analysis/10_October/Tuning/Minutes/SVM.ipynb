{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM) Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
    "\n",
    "# Set working directory\n",
    "month_file = '6_October'\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(\"/Users/mau/Library/CloudStorage/Dropbox/Mac/Documents/Dissertation/Chapter 2/Entire_Data/By month/\"+month_file+\"/Ending Balances/Per_Player\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataframes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[612 362]\n",
      " [307 629]]\n",
      "Accuracy:  0.6497382198952879\n",
      "Precision:  0.6503268260920647\n",
      "Recall:  0.6501726513276822\n",
      "F1 Score:  0.649710470197058\n"
     ]
    }
   ],
   "source": [
    "# Filter Columns\n",
    "filter = ['session_time', 'gender', 'age_gen', 'day', 'timeofday', 'first_outcome',\n",
    "        'first_wager','first_p/b', 'last_outcome', 'last_wager', 'last_p/b',\n",
    "        'beginning_amt', 'ending_amt', 'ending_balance', 'ave_slotdenom', \n",
    "        'std_slotdenom', 'min_slotdenom', 'max_slotdenom', 'ave_theo_payback',\n",
    "        'min_theo_payback', 'max_theo_payback', 'ave_wageramt', 'std_wageramt',\n",
    "        'min_wager', 'max_wager', 'ave_p/b', 'std_p/b', 'max_p/b', 'max_profit', 'depletion_slope', \n",
    "        '#inc_slotdenom', '#dec_slotdenom', '#inc_maxbet', '#dec_maxbet', '#W', '#L', '#NH', '#D',\n",
    "        'w/min', 'l/min', '#2ws', '2ws_profit', '2ws_wgramt','2ws/min', \n",
    "        '#3ws', '3ws_profit', '3ws_wgramt', '3ws/min', '#4ws', '4ws_profit', '4ws_wgramt', '4ws/min', \n",
    "        'w/g', 'l/g', 'nh/g', 'd/g', 'ave_time_per_gamble', \n",
    "        'min_time_per_gamble', 'max_time_per_gamble', 'total_gambles',\n",
    "        'machines_changes', 'unique_machines', 'ave_time_per_machine', 'classification']\n",
    "\n",
    "# Columns NOT INCLUDED\n",
    "# 'playerkey', 'rank', 'age_range', '#W', '#L', '#NH', '#D','total_duration', 'total_gambles'\n",
    "\n",
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_1min_top_vs_ntop_players.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # # Encode age_generartion, first_outoce, last_outcome, time of day columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 3, 4, 7])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "## Handling Class Imbalance \n",
    "# Apply SMOTE - SMOTE generates synthetic samples for the minority class to balance the dataset:\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled , test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 25:] = sc.fit_transform(X_train[:, 25:])\n",
    "X_test[:, 25:] = sc.transform(X_test[:, 25:])\n",
    "\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[822 152]\n",
      " [113 823]]\n",
      "Accuracy: 0.8612565445026178\n",
      "Precision: 0.861623474564651\n",
      "Recall: 0.8616080047034873\n",
      "F1 Score: 0.8612565064709046\n",
      "Best Hyperparameters: {'C': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Define the SVM hyperparameters and their respective ranges\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],  # Regularization parameter\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']  # Kernel type\n",
    "}\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = SVC(random_state=0)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=svm_classifier, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the data to perform the search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score:', f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best Hyperparameters:', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "  Time &  Accuracy &  Precision &  Recall &  F1 Score \\\\\n",
      "\\midrule\n",
      " 1 min &     0.861 &      0.862 &   0.862 &     0.861 \\\\\n",
      " 5 min &     0.888 &      0.888 &   0.888 &     0.888 \\\\\n",
      "10 min &     0.894 &      0.894 &   0.894 &     0.894 \\\\\n",
      "15 min &     0.906 &      0.906 &   0.906 &     0.906 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/1skwx2kd29s4fxnxx7tt9r6w0000gn/T/ipykernel_4355/4226227117.py:75: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = results_df.to_latex(index=False, escape=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Summary Table of Results\n",
    "# Table creation \n",
    "# Define time intervals\n",
    "time_intervals = [1, 5, 10, 15]\n",
    "\n",
    "# Initialize lists to store results\n",
    "results = []\n",
    "for time_interval in time_intervals:\n",
    "    # Load dataset for the specific time interval\n",
    "    file_name = f'df_{time_interval}min_top_vs_ntop_players.parquet'\n",
    "    dataset = pd.read_parquet(file_name, columns=filter)\n",
    "\n",
    "    # Keep only session_time 1\n",
    "    dataset = dataset[dataset['session_time'] == 1]\n",
    "    # Drop age_range and playerkey\n",
    "    dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "    # Convert ave_time_per_machine to seconds\n",
    "    dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "    # # Seperate dependent and independent variables\n",
    "    X = dataset.iloc[:, :-1].values\n",
    "    y = dataset.iloc[:, -1].values\n",
    "\n",
    "    # Econde gender column (Binary)\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    # Binary Encode gender\n",
    "    X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "    # # # Encode age_generartion, first_outoce, last_outcome, time of day columns\n",
    "    ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 3, 4, 7])], remainder='passthrough')\n",
    "    X = np.array(ct.fit_transform(X))\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "    ## Handling Class Imbalance \n",
    "    # Apply SMOTE - SMOTE generates synthetic samples for the minority class to balance the dataset:\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled , test_size = 0.2, random_state = 1)\n",
    "\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    # Scale all columns except the encoded ones\n",
    "    X_train[:, 25:] = sc.fit_transform(X_train[:, 25:])\n",
    "    X_test[:, 25:] = sc.transform(X_test[:, 25:])\n",
    "\n",
    "    # Best hyperparameters from tuning\n",
    "    best_hyperparameters = best_params\n",
    "\n",
    "    # Initialize logistic regression model with best hyperparameters\n",
    "    classifier = SVC(random_state=0, **best_hyperparameters)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append results for this time interval\n",
    "    results.append([f'{time_interval} min', round(accuracy, 3), round(precision, 3), round(recall, 3), round(f1, 3)])\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "columns = ['Time', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "results_df = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "# Print the results as a table\n",
    "# print(results_df)\n",
    "\n",
    "# Print the results as a LaTeX table\n",
    "latex_table = results_df.to_latex(index=False, escape=False)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllllllll}\n",
      "\\toprule\n",
      "  Time &  CV 1 &  CV 2 &  CV 3 &  CV 4 &  CV 5 &  CV 6 &  CV 7 &  CV 8 &  CV 9 & CV 10 \\\\\n",
      "\\midrule\n",
      " 1 min & 0.749 & 0.768 & 0.839 & 0.872 & 0.858 & 0.885 & 0.798 & 0.857 & 0.865 & 0.875 \\\\\n",
      " 5 min & 0.812 & 0.826 & 0.835 & 0.881 & 0.889 & 0.894 & 0.861 & 0.854 & 0.893 & 0.890 \\\\\n",
      "10 min & 0.835 & 0.846 & 0.867 & 0.890 & 0.897 & 0.908 & 0.874 & 0.883 & 0.874 & 0.926 \\\\\n",
      "15 min & 0.851 & 0.871 & 0.869 & 0.899 & 0.903 & 0.906 & 0.870 & 0.890 & 0.874 & 0.915 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "  Time &  Mean_Accuracy &  Std_Accuracy &  Precision &  Recall &  F1 Score \\\\\n",
      "\\midrule\n",
      " 1 min &          0.836 &         0.046 &      0.841 &   0.836 &     0.836 \\\\\n",
      " 5 min &          0.863 &         0.029 &      0.869 &   0.863 &     0.863 \\\\\n",
      "10 min &          0.880 &         0.026 &      0.884 &   0.880 &     0.880 \\\\\n",
      "15 min &          0.885 &         0.019 &      0.889 &   0.885 &     0.885 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/1skwx2kd29s4fxnxx7tt9r6w0000gn/T/ipykernel_4355/2159850664.py:80: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = results_df.to_latex(index=False, escape=False)\n",
      "/var/folders/vp/1skwx2kd29s4fxnxx7tt9r6w0000gn/T/ipykernel_4355/2159850664.py:81: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table2 = cv_results_df.to_latex(index=False, escape=False)\n"
     ]
    }
   ],
   "source": [
    "## Summary Table of Results\n",
    "# Table creation \n",
    "# Define time intervals\n",
    "time_intervals = [1, 5, 10, 15]\n",
    "\n",
    "# Initialize lists to store results\n",
    "cvscores = []\n",
    "results = []\n",
    "for time_interval in time_intervals:\n",
    "    # Load dataset for the specific time interval\n",
    "    file_name = f'df_{time_interval}min_top_vs_ntop_players.parquet'\n",
    "    dataset = pd.read_parquet(file_name, columns=filter)\n",
    "\n",
    "    # Keep only session_time 1\n",
    "    dataset = dataset[dataset['session_time'] == 1]\n",
    "    # Drop age_range and playerkey\n",
    "    dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "    # Convert ave_time_per_machine to seconds\n",
    "    dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "    # # Seperate dependent and independent variables\n",
    "    X = dataset.iloc[:, :-1].values\n",
    "    y = dataset.iloc[:, -1].values\n",
    "\n",
    "    # Econde gender column (Binary)\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    # Binary Encode gender\n",
    "    X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "    # # # Encode age_generartion, first_outoce, last_outcome, time of day columns\n",
    "    ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 3, 4, 7])], remainder='passthrough')\n",
    "    X = np.array(ct.fit_transform(X))\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "    ## Handling Class Imbalance \n",
    "    # Apply SMOTE - SMOTE generates synthetic samples for the minority class to balance the dataset:\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    # Scale all columns except the encoded ones\n",
    "    X_resampled[:, 25:] = sc.fit_transform(X_resampled[:, 25:])\n",
    "\n",
    "    # Best hyperparameters from tuning\n",
    "    best_hyperparameters = best_params\n",
    "\n",
    "    classifier = SVC(random_state = 0, **best_hyperparameters)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    y_pred_cv = cross_val_predict(classifier, X_resampled, y_resampled, cv=10, n_jobs=-1)\n",
    "\n",
    "    # Perform 10-fold cross-validation\n",
    "    cv_scores = cross_val_score(classifier, X_resampled, y_resampled, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "    mean_accuracy = cv_scores.mean()\n",
    "    std_accuracy = cv_scores.std()\n",
    "    cv_scores = cv_scores.tolist()\n",
    "    cv_scores = [ '%.3f' % elem for elem in cv_scores]\n",
    "\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision = precision_score(y_resampled, y_pred_cv, average='macro')\n",
    "    recall = recall_score(y_resampled, y_pred_cv, average='macro')\n",
    "    f1 = f1_score(y_resampled, y_pred_cv, average='macro')\n",
    "\n",
    "    # Append results for this time interval\n",
    "    results.append([f'{time_interval} min', round(mean_accuracy, 3), round(std_accuracy, 3), round(precision, 3), round(recall, 3), round(f1, 3)])\n",
    "    cvscores.append([f'{time_interval} min', *cv_scores])\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "columns = ['Time', 'Mean_Accuracy', 'Std_Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "results_df = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "# Print the results as a table\n",
    "cv_columns = ['Time', 'CV 1', 'CV 2', 'CV 3', 'CV 4', 'CV 5', 'CV 6', 'CV 7', 'CV 8', 'CV 9', 'CV 10']\n",
    "cv_results_df = pd.DataFrame(cvscores, columns=cv_columns)\n",
    "\n",
    "# Print the results as a LaTeX table\n",
    "latex_table = results_df.to_latex(index=False, escape=False)\n",
    "latex_table2 = cv_results_df.to_latex(index=False, escape=False)\n",
    "print(latex_table2)\n",
    "print(latex_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
