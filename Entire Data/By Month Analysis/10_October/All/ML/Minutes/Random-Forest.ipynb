{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive-Bayese Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Set working directory\n",
    "month_file = '5_September'\n",
    "# Set working directory\n",
    "os.chdir(\"/Users/mau/Library/CloudStorage/Dropbox/Mac/Documents/Dissertation/Chapter 2/Entire_Data/By month/\"+month_file+\"/Ending Balances/Per_Player\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataframes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[209 131 105  68]\n",
      " [171 165 141  73]\n",
      " [162 141 135  99]\n",
      " [142 123 124 155]]\n",
      "Accuracy:  0.30970149253731344\n",
      "Precision:  0.3149825521657048\n",
      "Recall:  0.3109326315100839\n",
      "F1 Score:  0.30893979354791384\n"
     ]
    }
   ],
   "source": [
    "filter = ['session_time', 'gender', 'age_gen', 'first_outcome',\n",
    "        'first_wager','first_p/b', 'last_outcome', 'last_wager', 'last_p/b',\n",
    "        'beginning_amt', 'ending_amt', 'ending_balance', 'ave_slotdenom', \n",
    "        'std_slotdenom', 'min_slotdenom', 'max_slotdenom', 'ave_theo_payback',\n",
    "        'min_theo_payback', 'max_theo_payback', 'ave_wageramt', 'std_wageramt',\n",
    "        'min_wager', 'max_wager', 'ave_p/b', 'std_p/b', 'max_p/b', 'max_profit', 'depletion_slope', \n",
    "        '#inc_slotdenom', '#dec_slotdenom', '#inc_maxbet', '#dec_maxbet', \n",
    "        '#W', '#L', '#NH', '#D','w/g', 'l/g', 'nh/g', 'd/g', '#2ws', '2ws_profit', '2ws_wgramt', '#3ws',\n",
    "        '3ws_profit', '3ws_wgramt', '#4ws', '4ws_profit', '4ws_wgramt','ave_time_per_gamble', \n",
    "        'min_time_per_gamble', 'max_time_per_gamble',\n",
    "        'machines_changes', 'unique_machines',  'ave_time_per_machine', 'classification']\n",
    "\n",
    "# Columns NOT INCLUDED\n",
    "# 'playerkey', 'rank', 'age_range', '#W', '#L', '#NH', '#D','total_duration', 'total_gambles'\n",
    "\n",
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_1min_ALL.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 5])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[209 125 112  67]\n",
      " [201 143 121  85]\n",
      " [152 153 116 116]\n",
      " [116 103 119 206]]\n",
      "Accuracy:  0.314365671641791\n",
      "Precision:  0.31590568859020474\n",
      "Recall:  0.31552469389369653\n",
      "F1 Score:  0.3132051752951678\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_2min_ALL.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 5])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[230 126  94  63]\n",
      " [192 160 104  94]\n",
      " [164 136 131 106]\n",
      " [ 92 111 105 236]]\n",
      "Accuracy:  0.3530783582089552\n",
      "Precision:  0.353552466341197\n",
      "Recall:  0.35425588967897026\n",
      "F1 Score:  0.35101781507738417\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_3min_ALL.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 5])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[242 120  88  63]\n",
      " [192 147 141  70]\n",
      " [169 133 125 110]\n",
      " [ 88  82 104 270]]\n",
      "Accuracy:  0.3656716417910448\n",
      "Precision:  0.36360947086957285\n",
      "Recall:  0.3670264558968681\n",
      "F1 Score:  0.36225330161179714\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_4min_ALL.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 5])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[210 130 109  64]\n",
      " [205 131 119  95]\n",
      " [147 132 137 121]\n",
      " [ 88  76  97 283]]\n",
      "Accuracy:  0.35494402985074625\n",
      "Precision:  0.35039892881082135\n",
      "Recall:  0.35572004359846277\n",
      "F1 Score:  0.35095396700224274\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_5min_ALL.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 5])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remainder__x31: 0.14566662778490608\n",
      "remainder__x53: 0.14039426105214042\n",
      "remainder__x32: 0.11434736964889772\n",
      "remainder__x9: 0.09389945176717601\n",
      "remainder__x50: 0.04886270850344101\n",
      "remainder__x24: 0.04387029044675141\n",
      "remainder__x8: 0.04158404292546365\n",
      "encoder__x1_Millenials: 0.03803802636183364\n",
      "remainder__x10: 0.03564679808701736\n",
      "remainder__x35: 0.03210078152338738\n",
      "remainder__x48: 0.03196080718534931\n",
      "remainder__x22: 0.030829347952875286\n",
      "remainder__x26: 0.025312026128543073\n",
      "remainder__x23: 0.022944126910066465\n",
      "remainder__x15: 0.022792488043858604\n",
      "remainder__x25: 0.020121311092966266\n",
      "remainder__x17: 0.018989851860492225\n",
      "remainder__x18: 0.018371631867490933\n",
      "remainder__x36: 0.017905050740697502\n",
      "remainder__x33: 0.016925230374431353\n",
      "remainder__x16: 0.014300711536218346\n",
      "remainder__x20: 0.013029277965706253\n",
      "remainder__x3: 0.01216610288113843\n",
      "remainder__x21: 0.012131109296628927\n",
      "remainder__x34: 0.012061122127609935\n",
      "remainder__x7: 0.011454566662778476\n",
      "remainder__x40: 0.01117461798670243\n",
      "remainder__x38: 0.011092966289513562\n",
      "remainder__x37: 0.010917998366966043\n",
      "remainder__x19: 0.010101481395077539\n",
      "remainder__x41: 0.009063338387962194\n",
      "encoder__x1_Baby Boomers: 0.00900501574711302\n",
      "remainder__x6: 0.00824682141607369\n",
      "remainder__x11: 0.008095182549865843\n",
      "remainder__x4: 0.008036859909016657\n",
      "remainder__x14: 0.00712702671176949\n",
      "remainder__x49: 0.006602122944126898\n",
      "remainder__x13: 0.005645631634200376\n",
      "remainder__x0: 0.00555231540884169\n",
      "encoder__x5_loss: 0.0037443135425171857\n",
      "encoder__x1_Gen X: 0.0035576810917998134\n",
      "remainder__x51: 0.0023562346903067354\n",
      "remainder__x52: 0.002286247521287732\n",
      "encoder__x2_loss: 0.0019129826198530098\n",
      "remainder__x29: 0.0019129826198529987\n",
      "remainder__x39: 0.0016680275282864865\n",
      "encoder__x5_gain: 0.0014114079085500997\n",
      "encoder__x5_near-hit: 0.0013180916831914136\n",
      "remainder__x12: 0.0012247754578327385\n",
      "encoder__x2_near-hit: 0.0009914848944360232\n",
      "encoder__x2_gain: 0.0008281815000583004\n",
      "remainder__x30: 0.000758194331039308\n",
      "encoder__x5_draw: 0.0007348652746996254\n",
      "remainder__x43: 0.0006765426338504299\n",
      "remainder__x44: 0.0005948909366615962\n",
      "remainder__x28: 0.0004315875422838844\n",
      "remainder__x46: 0.00037326490143470005\n",
      "remainder__x42: 0.00027994867607602505\n",
      "encoder__x1_Silent: 0.00013997433803798477\n",
      "encoder__x1_Gen Z: 9.331622535867501e-05\n",
      "encoder__x2_draw: 6.998716901900348e-05\n",
      "remainder__x47: 2.3329056339671528e-05\n",
      "remainder__x27: 1.1664528169830212e-05\n",
      "remainder__x45: -0.00011664528169841315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(classifier, X_train, y_train, n_repeats=10, random_state=42)\n",
    "\n",
    "# Get feature importances and feature names\n",
    "importances = result.importances_mean\n",
    "feature_names = ct.get_feature_names_out()\n",
    "\n",
    "# Sort feature importances\n",
    "feature_importance = list(zip(feature_names, importances))\n",
    "feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print feature importances\n",
    "for feature, importance in feature_importance:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[210 130 109  64]\n",
      " [205 131 119  95]\n",
      " [147 132 137 121]\n",
      " [ 88  76  97 283]]\n",
      "Accuracy:  0.35494402985074625\n",
      "Precision:  0.35039892881082135\n",
      "Recall:  0.35572004359846277\n",
      "F1 Score:  0.35095396700224274\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_5min_ALL.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 5])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
