{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Set working directory\n",
    "month_file = '5_September'\n",
    "# Set working directory\n",
    "os.chdir(\"/Users/mau/Library/CloudStorage/Dropbox/Mac/Documents/Dissertation/Chapter 2/Entire_Data/By month/\"+month_file+\"/Ending Balances/Per_Player\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataframes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[268  62  95  88]\n",
      " [212  74 130 134]\n",
      " [166  83 121 167]\n",
      " [122  64 108 250]]\n",
      "Accuracy:  0.33255597014925375\n",
      "Precision:  0.3170496406977683\n",
      "Recall:  0.33546182915368233\n",
      "F1 Score:  0.31573655605084117\n"
     ]
    }
   ],
   "source": [
    "filter = ['session_time', 'gender', 'age_gen', 'first_outcome',\n",
    "        'first_wager','first_p/b', 'last_outcome', 'last_wager', 'last_p/b',\n",
    "        'beginning_amt', 'ending_amt', 'ending_balance', 'ave_slotdenom', \n",
    "        'std_slotdenom', 'min_slotdenom', 'max_slotdenom', 'ave_theo_payback',\n",
    "        'min_theo_payback', 'max_theo_payback', 'ave_wageramt', 'std_wageramt',\n",
    "        'min_wager', 'max_wager', 'ave_p/b', 'std_p/b', 'max_p/b', 'max_profit', 'depletion_slope', \n",
    "        '#inc_slotdenom', '#dec_slotdenom', '#inc_maxbet', '#dec_maxbet', \n",
    "        '#W', '#L', '#NH', '#D','w/g', 'l/g', 'nh/g', 'd/g', '#2ws', '2ws_profit', '2ws_wgramt', '#3ws',\n",
    "        '3ws_profit', '3ws_wgramt', '#4ws', '4ws_profit', '4ws_wgramt','ave_time_per_gamble', \n",
    "        'min_time_per_gamble', 'max_time_per_gamble',\n",
    "        'machines_changes', 'unique_machines',  'ave_time_per_machine', 'classification']\n",
    "\n",
    "# Columns NOT INCLUDED\n",
    "# 'playerkey', 'rank', 'age_range', '#W', '#L', '#NH', '#D','total_duration', 'total_gambles'\n",
    "\n",
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_1min_ALL.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 5])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0, max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[268  65 107  73]\n",
      " [212  74 156 108]\n",
      " [162  77 161 137]\n",
      " [101  53 121 269]]\n",
      "Accuracy:  0.36007462686567165\n",
      "Precision:  0.3473669992967842\n",
      "Recall:  0.36281542072997763\n",
      "F1 Score:  0.3451855124711639\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_2min_ALL.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 5])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0, max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[267  76  97  73]\n",
      " [210  83 162  95]\n",
      " [161  84 150 142]\n",
      " [ 65  50 119 310]]\n",
      "Accuracy:  0.37779850746268656\n",
      "Precision:  0.36179205327197966\n",
      "Recall:  0.3801398693203547\n",
      "F1 Score:  0.3625991756960232\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_3min_ALL.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 5])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0, max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[266  68 102  77]\n",
      " [208  93 159  90]\n",
      " [164  85 156 132]\n",
      " [ 55  40 113 336]]\n",
      "Accuracy:  0.3969216417910448\n",
      "Precision:  0.38312167248060874\n",
      "Recall:  0.3989398199322616\n",
      "F1 Score:  0.38149972753736466\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_4min_ALL.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 5])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0, max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[258  84  94  77]\n",
      " [206  95 151  98]\n",
      " [160  84 161 132]\n",
      " [ 41  43  99 361]]\n",
      "Accuracy:  0.408115671641791\n",
      "Precision:  0.38941462100416624\n",
      "Recall:  0.4097669926931595\n",
      "F1 Score:  0.39118096532373364\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_5min_ALL.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 5])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0, max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remainder__x32: 0.03190248454450016\n",
      "remainder__x17: 0.02671176950892336\n",
      "remainder__x15: 0.024542167269333948\n",
      "remainder__x53: 0.023748979353785133\n",
      "remainder__x31: 0.01313425871923481\n",
      "remainder__x24: 0.011839496092383061\n",
      "remainder__x34: 0.008561763676659274\n",
      "remainder__x50: 0.007896885570978656\n",
      "remainder__x16: 0.007686924063921607\n",
      "remainder__x23: 0.00748862708503441\n",
      "remainder__x18: 0.007127026711769502\n",
      "remainder__x33: 0.0069403942610521355\n",
      "remainder__x52: 0.0068937361483727925\n",
      "encoder__x1_Baby Boomers: 0.006392161437069865\n",
      "remainder__x22: 0.006158870873673156\n",
      "remainder__x11: 0.005995567479295449\n",
      "remainder__x10: 0.0037909716551965513\n",
      "remainder__x9: 0.0036859909016680125\n",
      "encoder__x1_Millenials: 0.0035226875072903174\n",
      "remainder__x29: 0.003406042225591982\n",
      "remainder__x0: 0.0033943776974221353\n",
      "remainder__x42: 0.0032893969438936243\n",
      "remainder__x6: 0.0031844161903650916\n",
      "remainder__x20: 0.003079435436836575\n",
      "remainder__x21: 0.0029627901551382285\n",
      "encoder__x1_Gen X: 0.0029394610987985457\n",
      "remainder__x8: 0.0029277965706287156\n",
      "remainder__x49: 0.002834480345270035\n",
      "remainder__x14: 0.0027761577044208563\n",
      "remainder__x13: 0.0025895252537034784\n",
      "remainder__x51: 0.002542867141024141\n",
      "encoder__x5_gain: 0.0025312026128543053\n",
      "encoder__x1_Silent: 0.002426221859325789\n",
      "encoder__x5_loss: 0.0021696022395893966\n",
      "remainder__x19: 0.0021462731832497363\n",
      "remainder__x30: 0.0015397177184182874\n",
      "remainder__x27: 0.0014813950775690976\n",
      "remainder__x43: 0.0014230724367199187\n",
      "encoder__x1_Gen Z: 0.001364749795870751\n",
      "remainder__x38: 0.0013530852677009265\n",
      "remainder__x45: 0.0013530852677009098\n",
      "remainder__x46: 0.0013064271550215667\n",
      "remainder__x48: 0.0012947626268517364\n",
      "remainder__x37: 0.001143123760643877\n",
      "remainder__x35: 0.0011197947043042056\n",
      "remainder__x25: 0.0009914848944360232\n",
      "remainder__x28: 0.000781523387378974\n",
      "remainder__x3: 0.0007698588592091382\n",
      "remainder__x12: 0.00044325207045375903\n",
      "remainder__x47: 0.00023329056339671528\n",
      "remainder__x4: 0.00019829697888720799\n",
      "remainder__x26: 0.00017496792254752535\n",
      "encoder__x2_draw: 0.0001283098098681934\n",
      "remainder__x7: 0.00012830980986818785\n",
      "remainder__x44: 0.00010498075352851632\n",
      "encoder__x2_near-hit: 6.998716901900903e-05\n",
      "encoder__x5_near-hit: 4.6658112679337506e-05\n",
      "remainder__x40: 1.1664528169835764e-05\n",
      "remainder__x41: -1.1664528169846867e-05\n",
      "remainder__x36: -0.00017496792254753646\n",
      "encoder__x2_loss: -0.00023329056339670972\n",
      "encoder__x5_draw: -0.0005249037676426038\n",
      "remainder__x39: -0.0005249037676426094\n",
      "encoder__x2_gain: -0.0005482328239822754\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(classifier, X_train, y_train, n_repeats=10, random_state=42)\n",
    "\n",
    "# Get feature importances and feature names\n",
    "importances = result.importances_mean\n",
    "feature_names = ct.get_feature_names_out()\n",
    "\n",
    "# Sort feature importances\n",
    "feature_importance = list(zip(feature_names, importances))\n",
    "feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print feature importances\n",
    "for feature, importance in feature_importance:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
