{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive-Bayese Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Set working directory\n",
    "month_file = '3_July'\n",
    "# Set working directory\n",
    "os.chdir(\"/Users/mau/Library/CloudStorage/Dropbox/Mac/Documents/Dissertation/Chapter 2/Entire_Data/By month/\"+month_file+\"/Ending Balances/Per_Player\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataframes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[393 163]\n",
      " [195 353]]\n",
      "Accuracy:  0.6757246376811594\n",
      "Precision:  0.6841085271317829\n",
      "Recall:  0.6441605839416058\n",
      "F1 Score:  0.6635338345864661\n",
      "True Positive (B20):  393\n",
      "True Negative (T20):  353\n",
      "False Positive:  163\n",
      "False Negative:  195\n"
     ]
    }
   ],
   "source": [
    "filter = ['session_time', 'gender',  'sim_play', 'age_gen', 'first_outcome',\n",
    "        'first_wager','first_p/b', 'last_outcome', 'last_wager', 'last_p/b',\n",
    "        'beginning_amt', 'ending_amt', 'ending_balance', 'ave_slotdenom', \n",
    "        'std_slotdenom', 'min_slotdenom', 'max_slotdenom', 'ave_theo_payback',\n",
    "        'min_theo_payback', 'max_theo_payback', 'ave_wageramt', 'std_wageramt',\n",
    "        'min_wager', 'max_wager', 'ave_p/b', 'std_p/b', 'max_p/b', 'max_profit', 'depletion_slope', \n",
    "        '#inc_slotdenom', '#dec_slotdenom', '#inc_maxbet', '#dec_maxbet', \n",
    "        '#W', '#L', '#NH', '#D','w/g', 'l/g', 'nh/g', 'd/g', '#2ws', '2ws_profit', '2ws_wgramt', '#3ws',\n",
    "        '3ws_profit', '3ws_wgramt', '#4ws', '4ws_profit', '4ws_wgramt','ave_time_per_gamble', \n",
    "        'min_time_per_gamble', 'max_time_per_gamble',\n",
    "        'machines_changes', 'unique_machines',  'ave_time_per_machine', 'percentile']\n",
    "\n",
    "# Columns NOT INCLUDED\n",
    "# 'playerkey', 'rank', 'age_range', '#W', '#L', '#NH', '#D','total_duration', 'total_gambles'\n",
    "\n",
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_1min.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender and simplay\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "X[:, 1] = le.fit_transform(X[:, 1])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [2, 3, 6])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred))\n",
    "\n",
    "# Interpretation of confusion matrix\n",
    "print('True Positive (B20): ', cm[0][0])\n",
    "print('True Negative (T20): ', cm[1][1])\n",
    "print('False Positive: ', cm[0][1])\n",
    "print('False Negative: ', cm[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[414 142]\n",
      " [170 378]]\n",
      "Accuracy:  0.717391304347826\n",
      "Precision:  0.7269230769230769\n",
      "Recall:  0.6897810218978102\n",
      "F1 Score:  0.7078651685393258\n",
      "True Positive (B20):  414\n",
      "True Negative (T20):  378\n",
      "False Positive:  142\n",
      "False Negative:  170\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_2min.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender and simplay\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "X[:, 1] = le.fit_transform(X[:, 1])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [2, 3, 6])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred))\n",
    "\n",
    "# Interpretation of confusion matrix\n",
    "print('True Positive (B20): ', cm[0][0])\n",
    "print('True Negative (T20): ', cm[1][1])\n",
    "print('False Positive: ', cm[0][1])\n",
    "print('False Negative: ', cm[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[448 108]\n",
      " [178 370]]\n",
      "Accuracy:  0.7409420289855072\n",
      "Precision:  0.7740585774058577\n",
      "Recall:  0.6751824817518248\n",
      "F1 Score:  0.7212475633528265\n",
      "True Positive (B20):  448\n",
      "True Negative (T20):  370\n",
      "False Positive:  108\n",
      "False Negative:  178\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_3min.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender and simplay\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "X[:, 1] = le.fit_transform(X[:, 1])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [2, 3, 6])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred))\n",
    "\n",
    "# Interpretation of confusion matrix\n",
    "print('True Positive (B20): ', cm[0][0])\n",
    "print('True Negative (T20): ', cm[1][1])\n",
    "print('False Positive: ', cm[0][1])\n",
    "print('False Negative: ', cm[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[456 100]\n",
      " [152 396]]\n",
      "Accuracy:  0.7717391304347826\n",
      "Precision:  0.7983870967741935\n",
      "Recall:  0.7226277372262774\n",
      "F1 Score:  0.7586206896551723\n",
      "True Positive (B20):  456\n",
      "True Negative (T20):  396\n",
      "False Positive:  100\n",
      "False Negative:  152\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_4min.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender and simplay\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "X[:, 1] = le.fit_transform(X[:, 1])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [2, 3, 6])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred))\n",
    "\n",
    "# Interpretation of confusion matrix\n",
    "print('True Positive (B20): ', cm[0][0])\n",
    "print('True Negative (T20): ', cm[1][1])\n",
    "print('False Positive: ', cm[0][1])\n",
    "print('False Negative: ', cm[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remainder__x10: 0.11359200190430854\n",
      "remainder__x9: 0.08281361580576058\n",
      "encoder__x2_Millenials: 0.04629850035705789\n",
      "remainder__x49: 0.03691978100452278\n",
      "remainder__x51: 0.03180195191621049\n",
      "remainder__x55: 0.030111878124256176\n",
      "remainder__x18: 0.025160676029516826\n",
      "remainder__x11: 0.023470602237562532\n",
      "remainder__x27: 0.021947155439181177\n",
      "remainder__x50: 0.01990002380385626\n",
      "remainder__x33: 0.018162342299452572\n",
      "remainder__x16: 0.01811473458700317\n",
      "encoder__x2_Baby Boomers: 0.017043561056891265\n",
      "remainder__x17: 0.016924541775767733\n",
      "remainder__x52: 0.015139252558914596\n",
      "remainder__x25: 0.014044275172578002\n",
      "remainder__x37: 0.013877648179005053\n",
      "remainder__x26: 0.013758628897881497\n",
      "remainder__x23: 0.013639609616757952\n",
      "remainder__x7: 0.01354439419185911\n",
      "remainder__x24: 0.012092358962151916\n",
      "remainder__x36: 0.012068555105927203\n",
      "remainder__x32: 0.00873601523446802\n",
      "remainder__x19: 0.008497976672220953\n",
      "remainder__x4: 0.008021899547726762\n",
      "remainder__x38: 0.006450845036896036\n",
      "remainder__x22: 0.006308021899547767\n",
      "remainder__x21: 0.00616519876219952\n",
      "remainder__x12: 0.005974767912401846\n",
      "remainder__x39: 0.005831944775053599\n",
      "remainder__x8: 0.0048797905260652644\n",
      "encoder__x2_Gen X: 0.004855986669840573\n",
      "remainder__x5: 0.004213282551773445\n",
      "remainder__x34: 0.003903832420852216\n",
      "encoder__x2_Gen Z: 0.0038562247084028\n",
      "remainder__x20: 0.0038562247084028\n",
      "remainder__x0: 0.0036181861461557106\n",
      "remainder__x15: 0.0032135205903356724\n",
      "encoder__x3_loss: 0.0021899547726732193\n",
      "remainder__x14: 0.0021423470602238035\n",
      "encoder__x3_near-hit: 0.0019995239228755455\n",
      "remainder__x35: 0.0017852892168531808\n",
      "encoder__x6_loss: 0.0011663889550107775\n",
      "remainder__x53: 0.0011663889550107775\n",
      "remainder__x13: 0.000975958105213126\n",
      "encoder__x6_near-hit: 0.0009759581052131039\n",
      "encoder__x6_gain: 0.000833134967864868\n",
      "encoder__x2_Silent: 0.0007379195429660257\n",
      "encoder__x6_draw: 0.0007141156867413123\n",
      "remainder__x41: 0.0006665079742918967\n",
      "remainder__x40: 0.0005236848369436608\n",
      "remainder__x42: 0.000476077124494223\n",
      "remainder__x45: 0.0001666269935729936\n",
      "encoder__x3_gain: 0.00011901928112357796\n",
      "remainder__x43: 7.141156867414011e-05\n",
      "remainder__x1: 4.7607712449426745e-05\n",
      "encoder__x3_draw: 2.3803856224746678e-05\n",
      "remainder__x44: 2.3803856224713373e-05\n",
      "remainder__x54: 2.3803856224713373e-05\n",
      "remainder__x28: 0.0\n",
      "remainder__x29: 0.0\n",
      "remainder__x30: 0.0\n",
      "remainder__x31: 0.0\n",
      "remainder__x46: 0.0\n",
      "remainder__x47: 0.0\n",
      "remainder__x48: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(classifier, X_train, y_train, n_repeats=10, random_state=42)\n",
    "\n",
    "# Get feature importances and feature names\n",
    "importances = result.importances_mean\n",
    "feature_names = ct.get_feature_names_out()\n",
    "\n",
    "# Sort feature importances\n",
    "feature_importance = list(zip(feature_names, importances))\n",
    "feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print feature importances\n",
    "for feature, importance in feature_importance:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[482  74]\n",
      " [143 405]]\n",
      "Accuracy:  0.8034420289855072\n",
      "Precision:  0.8455114822546973\n",
      "Recall:  0.7390510948905109\n",
      "F1 Score:  0.7887049659201558\n",
      "True Positive (B20):  482\n",
      "True Negative (T20):  405\n",
      "False Positive:  74\n",
      "False Negative:  143\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_5min.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender and simplay\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "X[:, 1] = le.fit_transform(X[:, 1])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [2, 3, 6])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred))\n",
    "\n",
    "# Interpretation of confusion matrix\n",
    "print('True Positive (B20): ', cm[0][0])\n",
    "print('True Negative (T20): ', cm[1][1])\n",
    "print('False Positive: ', cm[0][1])\n",
    "print('False Negative: ', cm[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remainder__x33: 0.08205586592178767\n",
      "remainder__x55: 0.0774301675977653\n",
      "remainder__x10: 0.04227932960893851\n",
      "remainder__x9: 0.0333184357541899\n",
      "remainder__x32: 0.030726256983240174\n",
      "remainder__x23: 0.01910614525139661\n",
      "remainder__x26: 0.017050279329608897\n",
      "remainder__x25: 0.01633519553072621\n",
      "remainder__x36: 0.015262569832402196\n",
      "remainder__x34: 0.014279329608938508\n",
      "remainder__x49: 0.01329608938547482\n",
      "remainder__x37: 0.012424581005586554\n",
      "remainder__x24: 0.011865921787709455\n",
      "remainder__x50: 0.010703910614525091\n",
      "remainder__x27: 0.01063687150837983\n",
      "encoder__x2_Millenials: 0.010480446927374243\n",
      "remainder__x39: 0.00974301675977648\n",
      "remainder__x11: 0.009698324022346317\n",
      "remainder__x51: 0.009072625698323978\n",
      "remainder__x16: 0.008558659217877051\n",
      "remainder__x17: 0.008446927374301638\n",
      "remainder__x19: 0.008312849162011127\n",
      "encoder__x2_Baby Boomers: 0.008245810055865877\n",
      "remainder__x52: 0.007530726256983189\n",
      "remainder__x7: 0.00730726256983234\n",
      "remainder__x18: 0.006569832402234588\n",
      "remainder__x20: 0.006234636871508314\n",
      "remainder__x38: 0.004692737430167559\n",
      "remainder__x21: 0.004424581005586547\n",
      "remainder__x35: 0.004156424581005536\n",
      "remainder__x42: 0.004134078212290481\n",
      "remainder__x4: 0.004111731843575384\n",
      "remainder__x8: 0.0038435754189943827\n",
      "remainder__x54: 0.0038212290502792844\n",
      "remainder__x41: 0.0036648044692737082\n",
      "remainder__x12: 0.003642458100558621\n",
      "remainder__x22: 0.0035977653631284355\n",
      "remainder__x5: 0.0029944134078211727\n",
      "remainder__x15: 0.002726256983240172\n",
      "encoder__x2_Gen X: 0.002122905027932942\n",
      "remainder__x0: 0.0020335195530725826\n",
      "remainder__x14: 0.0013184357541899173\n",
      "remainder__x53: 0.00129608938547483\n",
      "encoder__x3_loss: 0.001273743016759743\n",
      "encoder__x6_gain: 0.0011620111731843075\n",
      "encoder__x3_gain: 0.0008938547486033066\n",
      "remainder__x30: 0.0008715083798881973\n",
      "remainder__x43: 0.0007374301675977191\n",
      "encoder__x6_near-hit: 0.0007374301675977079\n",
      "remainder__x45: 0.0004022346368714569\n",
      "remainder__x40: 0.00022346368715079335\n",
      "remainder__x28: 0.00022346368715076004\n",
      "encoder__x2_Gen Z: 0.00020111731843570625\n",
      "remainder__x44: 0.00020111731843568402\n",
      "encoder__x3_draw: 0.00017877094972061912\n",
      "remainder__x1: 0.00017877094972060804\n",
      "encoder__x3_near-hit: 0.00011173184357538002\n",
      "encoder__x6_loss: 0.00011173184357538002\n",
      "remainder__x31: 4.469273743015201e-05\n",
      "encoder__x2_Silent: 0.0\n",
      "remainder__x29: 0.0\n",
      "remainder__x46: 0.0\n",
      "remainder__x47: 0.0\n",
      "remainder__x48: 0.0\n",
      "remainder__x13: -1.1102230246251566e-17\n",
      "encoder__x6_draw: -2.2346368715087107e-05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(classifier, X_train, y_train, n_repeats=10, random_state=42)\n",
    "\n",
    "# Get feature importances and feature names\n",
    "importances = result.importances_mean\n",
    "feature_names = ct.get_feature_names_out()\n",
    "\n",
    "# Sort feature importances\n",
    "feature_importance = list(zip(feature_names, importances))\n",
    "feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print feature importances\n",
    "for feature, importance in feature_importance:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[526  30]\n",
      " [ 95 453]]\n",
      "Accuracy:  0.8867753623188406\n",
      "Precision:  0.937888198757764\n",
      "Recall:  0.8266423357664233\n",
      "F1 Score:  0.8787584869059165\n",
      "True Positive (B20):  526\n",
      "True Negative (T20):  453\n",
      "False Positive:  30\n",
      "False Negative:  95\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_10min.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender and simplay\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "X[:, 1] = le.fit_transform(X[:, 1])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [2, 3, 6])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred))\n",
    "\n",
    "# Interpretation of confusion matrix\n",
    "print('True Positive (B20): ', cm[0][0])\n",
    "print('True Negative (T20): ', cm[1][1])\n",
    "print('False Positive: ', cm[0][1])\n",
    "print('False Negative: ', cm[1][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[542  14]\n",
      " [ 90 458]]\n",
      "Accuracy:  0.9057971014492754\n",
      "Precision:  0.9703389830508474\n",
      "Recall:  0.8357664233576643\n",
      "F1 Score:  0.8980392156862744\n",
      "True Positive (B20):  542\n",
      "True Negative (T20):  458\n",
      "False Positive:  14\n",
      "False Negative:  90\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_15min.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender and simplay\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "X[:, 1] = le.fit_transform(X[:, 1])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [2, 3, 6])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred))\n",
    "\n",
    "# Interpretation of confusion matrix\n",
    "print('True Positive (B20): ', cm[0][0])\n",
    "print('True Negative (T20): ', cm[1][1])\n",
    "print('False Positive: ', cm[0][1])\n",
    "print('False Negative: ', cm[1][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
