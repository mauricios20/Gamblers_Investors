{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Set working directory\n",
    "month_file = '3_July'\n",
    "# Set working directory\n",
    "os.chdir(\"/Users/mau/Library/CloudStorage/Dropbox/Mac/Documents/Dissertation/Chapter 2/Entire_Data/By month/\"+month_file+\"/Ending Balances/Per_Player\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataframes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2326    5]\n",
      " [ 265    2]]\n",
      "Accuracy:  0.8960739030023095\n",
      "Precision:  0.5917185863152672\n",
      "Recall:  0.5026728172795588\n",
      "F1 Score:  0.4798713952253698\n"
     ]
    }
   ],
   "source": [
    "# Filter Columns\n",
    "filter = ['session_time', 'gender', 'age_gen', 'day', 'timeofday', 'first_outcome',\n",
    "        'first_wager','first_p/b', 'last_outcome', 'last_wager', 'last_p/b',\n",
    "        'beginning_amt', 'ending_amt', 'ending_balance', 'ave_slotdenom', \n",
    "        'std_slotdenom', 'min_slotdenom', 'max_slotdenom', 'ave_theo_payback',\n",
    "        'min_theo_payback', 'max_theo_payback', 'ave_wageramt', 'std_wageramt',\n",
    "        'min_wager', 'max_wager', 'ave_p/b', 'std_p/b', 'max_p/b', 'max_profit', 'depletion_slope', \n",
    "        '#inc_slotdenom', '#dec_slotdenom', '#inc_maxbet', '#dec_maxbet', '#W', '#L', '#NH', '#D',\n",
    "        'w/min', 'l/min', '#2ws', '2ws_profit', '2ws_wgramt','2ws/min', \n",
    "        '#3ws', '3ws_profit', '3ws_wgramt', '3ws/min', '#4ws', '4ws_profit', '4ws_wgramt', '4ws/min', \n",
    "        'w/g', 'l/g', 'nh/g', 'd/g', 'ave_time_per_gamble', \n",
    "        'min_time_per_gamble', 'max_time_per_gamble', 'total_gambles',\n",
    "        'machines_changes', 'unique_machines', 'ave_time_per_machine', 'classification']\n",
    "\n",
    "# Columns NOT INCLUDED\n",
    "# 'playerkey', 'rank', 'age_range', '#W', '#L', '#NH', '#D','total_duration', 'total_gambles'\n",
    "\n",
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_1min_top_vs_ntop_players.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # # Encode age_generartion, first_outoce, last_outcome, time of day columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 3, 4, 7])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 25:] = sc.fit_transform(X_train[:, 25:])\n",
    "X_test[:, 25:] = sc.transform(X_test[:, 25:])\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0, max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2324    7]\n",
      " [ 265    2]]\n",
      "Accuracy:  0.8953040800615858\n",
      "Precision:  0.5599330500836874\n",
      "Recall:  0.5022438168505584\n",
      "F1 Score:  0.47960410038882995\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_2min_top_vs_ntop_players.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # # Encode age_generartion, first_outoce, last_outcome, time of day columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 3, 4, 7])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 25:] = sc.fit_transform(X_train[:, 25:])\n",
    "X_test[:, 25:] = sc.transform(X_test[:, 25:])\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0, max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2326    5]\n",
      " [ 263    4]]\n",
      "Accuracy:  0.8968437259430331\n",
      "Precision:  0.6714304107119866\n",
      "Recall:  0.5064181356316187\n",
      "F1 Score:  0.48725698126546485\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_3min_top_vs_ntop_players.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # # Encode age_generartion, first_outoce, last_outcome, time of day columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 3, 4, 7])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 25:] = sc.fit_transform(X_train[:, 25:])\n",
    "X_test[:, 25:] = sc.transform(X_test[:, 25:])\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0, max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2323    8]\n",
      " [ 260    7]]\n",
      "Accuracy:  0.8968437259430331\n",
      "Precision:  0.6830042586140147\n",
      "Recall:  0.511392612516208\n",
      "F1 Score:  0.4975536677664337\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_4min_top_vs_ntop_players.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # # Encode age_generartion, first_outoce, last_outcome, time of day columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 3, 4, 7])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 25:] = sc.fit_transform(X_train[:, 25:])\n",
    "X_test[:, 25:] = sc.transform(X_test[:, 25:])\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0, max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2325    6]\n",
      " [ 261    6]]\n",
      "Accuracy:  0.8972286374133949\n",
      "Precision:  0.6995359628770301\n",
      "Recall:  0.5099489537691785\n",
      "F1 Score:  0.49435467469674005\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_5min_top_vs_ntop_players.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # # Encode age_generartion, first_outoce, last_outcome, time of day columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 3, 4, 7])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 25:] = sc.fit_transform(X_train[:, 25:])\n",
    "X_test[:, 25:] = sc.transform(X_test[:, 25:])\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0, max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2315   16]\n",
      " [ 252   15]]\n",
      "Accuracy:  0.8968437259430331\n",
      "Precision:  0.6928509493949258\n",
      "Recall:  0.524657884208446\n",
      "F1 Score:  0.5229774651206766\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_10min_top_vs_ntop_players.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # # Encode age_generartion, first_outoce, last_outcome, time of day columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 3, 4, 7])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 25:] = sc.fit_transform(X_train[:, 25:])\n",
    "X_test[:, 25:] = sc.transform(X_test[:, 25:])\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0, max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2312   19]\n",
      " [ 248   19]]\n",
      "Accuracy:  0.8972286374133949\n",
      "Precision:  0.7015625\n",
      "Recall:  0.5315050202690652\n",
      "F1 Score:  0.5350000502763523\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_15min_top_vs_ntop_players.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # # Encode age_generartion, first_outoce, last_outcome, time of day columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 3, 4, 7])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 25:] = sc.fit_transform(X_train[:, 25:])\n",
    "X_test[:, 25:] = sc.transform(X_test[:, 25:])\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0, max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Table of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "  Time &  Accuracy &  Precision &  Recall &  F1 Score \\\\\n",
      "\\midrule\n",
      " 1 min &     0.896 &      0.592 &   0.503 &     0.480 \\\\\n",
      " 2 min &     0.895 &      0.560 &   0.502 &     0.480 \\\\\n",
      " 3 min &     0.897 &      0.671 &   0.506 &     0.487 \\\\\n",
      " 4 min &     0.897 &      0.683 &   0.511 &     0.498 \\\\\n",
      " 5 min &     0.897 &      0.700 &   0.510 &     0.494 \\\\\n",
      "10 min &     0.897 &      0.693 &   0.525 &     0.523 \\\\\n",
      "15 min &     0.897 &      0.702 &   0.532 &     0.535 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/1skwx2kd29s4fxnxx7tt9r6w0000gn/T/ipykernel_67143/3894158978.py:66: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = results_df.to_latex(index=False, escape=False)\n"
     ]
    }
   ],
   "source": [
    "# Table creation \n",
    "# Define time intervals\n",
    "time_intervals = [1, 2, 3, 4, 5, 10, 15]\n",
    "\n",
    "# Initialize lists to store results\n",
    "results = []\n",
    "for time_interval in time_intervals:\n",
    "    # Load dataset for the specific time interval\n",
    "    file_name = f'df_{time_interval}min_top_vs_ntop_players.parquet'\n",
    "    dataset = pd.read_parquet(file_name, columns=filter)\n",
    "\n",
    "    # Keep only session_time 1\n",
    "    dataset = dataset[dataset['session_time'] == 1]\n",
    "    # Drop age_range and playerkey\n",
    "    dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "    # Convert ave_time_per_machine to seconds\n",
    "    dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "    # # Seperate dependent and independent variables\n",
    "    X = dataset.iloc[:, :-1].values\n",
    "    y = dataset.iloc[:, -1].values\n",
    "\n",
    "    # Econde gender column (Binary)\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    # Binary Encode gender\n",
    "    X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "    # # # Encode age_generartion, first_outoce, last_outcome, time of day columns\n",
    "    ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 3, 4, 7])], remainder='passthrough')\n",
    "    X = np.array(ct.fit_transform(X))\n",
    "\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    # Scale all columns except the encoded ones\n",
    "    X_train[:, 25:] = sc.fit_transform(X_train[:, 25:])\n",
    "    X_test[:, 25:] = sc.transform(X_test[:, 25:])\n",
    "\n",
    "    classifier = LogisticRegression(random_state = 0, max_iter=1000) \n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append results for this time interval\n",
    "    results.append([f'{time_interval} min', round(accuracy, 3), round(precision, 3), round(recall, 3), round(f1, 3)])\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "columns = ['Time', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "results_df = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "# Print the results as a table\n",
    "# print(results_df)\n",
    "\n",
    "# Print the results as a LaTeX table\n",
    "latex_table = results_df.to_latex(index=False, escape=False)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remainder__x15: 0.005582290664100109\n",
      "remainder__x18: 0.003869104908565968\n",
      "remainder__x21: 0.002319538017324396\n",
      "remainder__x29: 0.0022810394610202735\n",
      "remainder__x30: 0.0022329162656400726\n",
      "remainder__x38: 0.001530317613089549\n",
      "remainder__x52: 0.001472569778633337\n",
      "remainder__x33: 0.0013185755534167675\n",
      "remainder__x19: 0.0012223291626564437\n",
      "remainder__x14: 0.0011453320500481646\n",
      "remainder__x56: 0.0009624639076035058\n",
      "remainder__x27: 0.0008854667949951933\n",
      "remainder__x9: 0.0008469682386910926\n",
      "remainder__x28: 0.000798845043310914\n",
      "encoder__x1_Baby Boomers: 0.0007699711260827913\n",
      "remainder__x20: 0.0007025986525505679\n",
      "remainder__x55: 0.0006544754571703893\n",
      "remainder__x35: 0.0005582290664100431\n",
      "remainder__x12: 0.0005486044273340207\n",
      "remainder__x16: 0.0005486044273340207\n",
      "remainder__x24: 0.00048123195380177507\n",
      "remainder__x23: 0.0004234841193455852\n",
      "remainder__x11: 0.0003176130895092055\n",
      "encoder__x61_afternoon: 0.00029836381135712743\n",
      "remainder__x31: 0.0002694898941290047\n",
      "remainder__x34: 0.0002598652550529712\n",
      "remainder__x10: 0.0002502406159769488\n",
      "encoder__x1_Silent: 0.0002406159769009264\n",
      "remainder__x59: 0.0002406159769009042\n",
      "remainder__x57: 0.00018286814244471427\n",
      "remainder__x37: 0.00014436958614056917\n",
      "remainder__x8: 0.00014436958614055806\n",
      "remainder__x48: 0.00013474494706452455\n",
      "remainder__x40: 0.00013474494706451346\n",
      "remainder__x45: 0.00013474494706451346\n",
      "encoder__x61_morning: 0.00010587102983641294\n",
      "remainder__x60: 0.00010587102983641294\n",
      "remainder__x25: 9.624639076036834e-05\n",
      "remainder__x6: 8.662175168432374e-05\n",
      "remainder__x13: 7.699711260831244e-05\n",
      "remainder__x39: 7.699711260830133e-05\n",
      "encoder__x61_night: 5.774783445624543e-05\n",
      "encoder__x2_draw: 5.7747834456212124e-05\n",
      "remainder__x53: 4.812319538022303e-05\n",
      "encoder__x2_loss: 4.812319538018972e-05\n",
      "encoder__x5_near-hit: 3.8498556304189525e-05\n",
      "encoder__x1_Gen Z: 2.8873917228144917e-05\n",
      "remainder__x42: 2.887391722810051e-05\n",
      "encoder__x2_near-hit: 0.0\n",
      "remainder__x4: 0.0\n",
      "remainder__x43: 0.0\n",
      "remainder__x46: 0.0\n",
      "remainder__x49: -9.624639075989094e-06\n",
      "encoder__x1_Gen X: -9.6246390760113e-06\n",
      "encoder__x2_gain: -9.6246390760224e-06\n",
      "encoder__x5_draw: -9.624639076033504e-06\n",
      "remainder__x26: -2.887391722810051e-05\n",
      "remainder__x7: -3.849855630412291e-05\n",
      "remainder__x54: -4.8123195380156417e-05\n",
      "remainder__x22: -5.774783445617881e-05\n",
      "encoder__x1_Millenials: -5.774783445618992e-05\n",
      "remainder__x51: -6.737247353223452e-05\n",
      "remainder__x0: -7.699711260824582e-05\n",
      "remainder__x50: -8.662175168426822e-05\n",
      "remainder__x3: -9.624639076033503e-05\n",
      "encoder__x61_evening: -0.00011549566891240204\n",
      "encoder__x5_loss: -0.00013474494706445795\n",
      "remainder__x58: -0.00013474494706446904\n",
      "remainder__x44: -0.00017324350336860305\n",
      "remainder__x36: -0.00020211742059669246\n",
      "encoder__x5_gain: -0.00024061597690083758\n",
      "remainder__x47: -0.0002887391722810051\n",
      "remainder__x41: -0.0002983638113570386\n",
      "remainder__x32: -0.000327237728585128\n",
      "remainder__x17: -0.0003464870067372061\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(classifier, X_train, y_train, n_repeats=10, random_state=42)\n",
    "\n",
    "# Get feature importances and feature names\n",
    "importances = result.importances_mean\n",
    "feature_names = ct.get_feature_names_out()\n",
    "\n",
    "# Sort feature importances\n",
    "feature_importance = list(zip(feature_names, importances))\n",
    "feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print feature importances\n",
    "for feature, importance in feature_importance:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
