{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
    "\n",
    "\n",
    "\n",
    "# Set working directory\n",
    "month_file = '3_July'\n",
    "# Set working directory\n",
    "os.chdir(\"/Users/mau/Library/CloudStorage/Dropbox/Mac/Documents/Dissertation/Chapter 2/Entire_Data/By month/\"+month_file+\"/Ending Balances/Per_Player\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataframes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2295   36]\n",
      " [ 249   18]]\n",
      "Accuracy:  0.8903002309468823\n",
      "Precision:  0.6177279874213837\n",
      "Recall:  0.5259858574465316\n",
      "F1 Score:  0.526843997124371\n"
     ]
    }
   ],
   "source": [
    "# Filter Columns\n",
    "filter = ['session_time', 'gender', 'age_gen', 'day', 'timeofday', 'first_outcome',\n",
    "        'first_wager','first_p/b', 'last_outcome', 'last_wager', 'last_p/b',\n",
    "        'beginning_amt', 'ending_amt', 'ending_balance', 'ave_slotdenom', \n",
    "        'std_slotdenom', 'min_slotdenom', 'max_slotdenom', 'ave_theo_payback',\n",
    "        'min_theo_payback', 'max_theo_payback', 'ave_wageramt', 'std_wageramt',\n",
    "        'min_wager', 'max_wager', 'ave_p/b', 'std_p/b', 'max_p/b', 'max_profit', 'depletion_slope', \n",
    "        '#inc_slotdenom', '#dec_slotdenom', '#inc_maxbet', '#dec_maxbet', '#W', '#L', '#NH', '#D',\n",
    "        'w/min', 'l/min', '#2ws', '2ws_profit', '2ws_wgramt','2ws/min', \n",
    "        '#3ws', '3ws_profit', '3ws_wgramt', '3ws/min', '#4ws', '4ws_profit', '4ws_wgramt', '4ws/min', \n",
    "        'w/g', 'l/g', 'nh/g', 'd/g', 'ave_time_per_gamble', \n",
    "        'min_time_per_gamble', 'max_time_per_gamble', 'total_gambles',\n",
    "        'machines_changes', 'unique_machines', 'ave_time_per_machine', 'classification']\n",
    "\n",
    "# Columns NOT INCLUDED\n",
    "# 'playerkey', 'rank', 'age_range', '#W', '#L', '#NH', '#D','total_duration', 'total_gambles'\n",
    "\n",
    "# Load dataset\n",
    "dataset = pd.read_parquet('df_5min_top_vs_ntop_players.parquet', columns=filter)\n",
    "\n",
    "# Keep only session_time 1\n",
    "dataset = dataset[dataset['session_time'] == 1]\n",
    "# Drop age_range and playerkey\n",
    "dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "# Convert ave_time_per_machine to seconds\n",
    "dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # # Encode age_generartion, first_outoce, last_outcome, time of day columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 3, 4, 7])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, random_state = 1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 25:] = sc.fit_transform(X_train[:, 25:])\n",
    "X_test[:, 25:] = sc.transform(X_test[:, 25:])\n",
    "\n",
    "## Handling Class Imbalance \n",
    "# Apply SMOTE - SMOTE generates synthetic samples for the minority class to balance the dataset:\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "classifier = RandomForestClassifier(random_state = 0)\n",
    "classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2295   36]\n",
      " [ 249   18]]\n",
      "Accuracy: 0.8903002309468823\n",
      "Precision: 0.6177279874213837\n",
      "Recall: 0.5259858574465316\n",
      "F1 Score: 0.526843997124371\n",
      "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameters and their respective ranges\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the data to perform the search\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score:', f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best Hyperparameters:', best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "  Time &  Accuracy &  Std. &  Precision &  Recall &  F1 Score \\\\\n",
      "\\midrule\n",
      " 1 min &     0.893 & 0.002 &      0.626 &   0.524 &     0.522 \\\\\n",
      " 5 min &     0.892 & 0.002 &      0.632 &   0.534 &     0.540 \\\\\n",
      "10 min &     0.894 & 0.005 &      0.667 &   0.549 &     0.562 \\\\\n",
      "15 min &     0.893 & 0.004 &      0.661 &   0.557 &     0.572 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/1skwx2kd29s4fxnxx7tt9r6w0000gn/T/ipykernel_87255/262123485.py:85: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(results_df.to_latex(index=False))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Define time intervals\n",
    "time_intervals = [1, 5, 10, 15]\n",
    "\n",
    "# Initialize lists to store results\n",
    "results = []\n",
    "\n",
    "for time_interval in time_intervals:\n",
    "    # Load dataset for the specific time interval\n",
    "    file_name = f'df_{time_interval}min_top_vs_ntop_players.parquet'\n",
    "    dataset = pd.read_parquet(file_name, columns=filter)\n",
    "\n",
    "    # Keep only session_time 1\n",
    "    dataset = dataset[dataset['session_time'] == 1]\n",
    "    # Drop age_range and playerkey\n",
    "    dataset = dataset.drop(['session_time'], axis=1)\n",
    "\n",
    "    # Convert ave_time_per_machine to seconds\n",
    "    dataset['ave_time_per_machine'] = dataset['ave_time_per_machine'].dt.total_seconds()\n",
    "\n",
    "    # # Seperate dependent and independent variables\n",
    "    X = dataset.iloc[:, :-1].values\n",
    "    y = dataset.iloc[:, -1].values\n",
    "\n",
    "    # Econde gender column (Binary)\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    # Binary Encode gender\n",
    "    X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "    # # # Encode age_generartion, first_outoce, last_outcome, time of day columns\n",
    "    ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 3, 4, 7])], remainder='passthrough')\n",
    "    X = np.array(ct.fit_transform(X))\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "    # Initialize stratified k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "    # Lists to store evaluation metrics for each fold\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Scale all columns except the encoded ones\n",
    "        X_train[:, 25:] = sc.fit_transform(X_train[:, 25:])\n",
    "        X_test[:, 25:] = sc.transform(X_test[:, 25:])\n",
    "\n",
    "        ## Handling Class Imbalance \n",
    "        # Apply SMOTE - SMOTE generates synthetic samples for the minority class to balance the dataset:\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        classifier = RandomForestClassifier(random_state=0, **best_params)\n",
    "        classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "        y_pred = classifier.predict(X_test)\n",
    "\n",
    "        # Calculate evaluation metrics for this fold\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "        recall_scores.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    # Calculate the average evaluation metrics over all folds\n",
    "    average_accuracy = np.mean(accuracy_scores)\n",
    "    std_accuracy = np.std(accuracy_scores)\n",
    "    average_precision = np.mean(precision_scores)\n",
    "    average_recall = np.mean(recall_scores)\n",
    "    average_f1 = np.mean(f1_scores)\n",
    "\n",
    "    # Append results for this time interval\n",
    "    results.append([f'{time_interval} min', round(average_accuracy, 3), round(std_accuracy, 3), round(average_precision, 3), round(average_recall, 3), round(average_f1, 3)])\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "columns = ['Time', 'Accuracy', 'Std.', 'Precision', 'Recall', 'F1 Score']\n",
    "results_df = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "# Print the results\n",
    "print(results_df.to_latex(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
