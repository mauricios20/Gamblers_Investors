{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "import counting_fns as cf\n",
    "\n",
    "\n",
    "# List of all the months\n",
    "months = ['2_June', '3_July', '4_August', '5_September', '6_October']\n",
    "\n",
    "# Define the path to the data directory and columns to keep\n",
    "data_path = \"/Users/mau/Library/CloudStorage/Dropbox/Mac/Documents/Dissertation/Chapter 2/Entire_Data/By month\"\n",
    "\n",
    "# Filter Desire Columns\n",
    "filter = ['session_time', 'gender',  'sim_play', 'age_gen', 'first_outcome',\n",
    "        'first_wager','first_p/b', 'last_outcome', 'last_wager', 'last_p/b',\n",
    "        'beginning_amt', 'ending_amt', 'ending_balance', 'ave_slotdenom', \n",
    "        'std_slotdenom', 'min_slotdenom', 'max_slotdenom', 'ave_theo_payback',\n",
    "        'min_theo_payback', 'max_theo_payback', 'ave_wageramt', 'std_wageramt',\n",
    "        'min_wager', 'max_wager', 'ave_p/b', 'std_p/b', 'max_p/b', 'max_profit', 'depletion_slope', \n",
    "        '#inc_slotdenom', '#dec_slotdenom', '#inc_maxbet', '#dec_maxbet', \n",
    "        '#W', '#L', '#NH', '#D','w/g', 'l/g', 'nh/g', 'd/g', '#2ws', '2ws_profit', '2ws_wgramt', '#3ws',\n",
    "        '3ws_profit', '3ws_wgramt', '#4ws', '4ws_profit', '4ws_wgramt','ave_time_per_gamble', \n",
    "        'min_time_per_gamble', 'max_time_per_gamble',\n",
    "        'machines_changes', 'unique_machines',  'ave_time_per_machine', 'percentile']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Months in training set: ['6_October', '4_August', '3_July', '2_June']\n",
      "Months in test set: ['5_September']\n"
     ]
    }
   ],
   "source": [
    "# Randomly select 3 months for training set\n",
    "# random.seed(350)\n",
    "months_train = random.sample(months, 4)\n",
    "\n",
    "# Print the months in the training set\n",
    "print(\"Months in training set:\", months_train)\n",
    "\n",
    "# Create a list of remaining months for the test set\n",
    "months_test = [month for month in months if month not in months_train]\n",
    "# Print the months in the test set\n",
    "print(\"Months in test set:\", months_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataframes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1614  587]\n",
      " [ 816 1502]]\n",
      "Accuracy:  0.689533082540385\n",
      "Precision:  0.7190043082814744\n",
      "Recall:  0.6479723899913719\n",
      "F1 Score:  0.6816428409348763\n",
      "True Positive (B20):  1614\n",
      "True Negative (T20):  1502\n",
      "False Positive:  587\n",
      "False Negative:  816\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "datasets = cf.load_and_preprocess_datasets(months, data_path, '1min', filter)\n",
    "\n",
    "# Create training and test sets\n",
    "dt_train = pd.concat([datasets['dtf'+month[1:]] for month in months_train])\n",
    "dt_test = pd.concat([datasets['dtf'+month[1:]] for month in months_test])\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X_train = dt_train.iloc[:, :-1].values\n",
    "y_train = dt_train.iloc[:, -1].values\n",
    "X_test = dt_test.iloc[:, :-1].values\n",
    "y_test = dt_test.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender and simplay\n",
    "X_train[:, 0] = le.fit_transform(X_train[:, 0])\n",
    "X_train[:, 1] = le.fit_transform(X_train[:, 1])\n",
    "X_test[:, 0] = le.fit_transform(X_test[:, 0])\n",
    "X_test[:, 1] = le.fit_transform(X_test[:, 1])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [2, 3, 6])], remainder='passthrough')\n",
    "X_train = np.array(ct.fit_transform(X_train))\n",
    "X_test = np.array(ct.transform(X_test))\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# # Feature Scaling\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred))\n",
    "\n",
    "# Interpretation of confusion matrix\n",
    "print('True Positive (B20): ', cm[0][0])\n",
    "print('True Negative (T20): ', cm[1][1])\n",
    "print('False Positive: ', cm[0][1])\n",
    "print('False Negative: ', cm[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1650  551]\n",
      " [ 715 1603]]\n",
      "Accuracy:  0.7198495242310246\n",
      "Precision:  0.744196843082637\n",
      "Recall:  0.691544434857636\n",
      "F1 Score:  0.7169051878354205\n",
      "True Positive (B20):  1650\n",
      "True Negative (T20):  1603\n",
      "False Positive:  551\n",
      "False Negative:  715\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets for 2min, named it datasets_2\n",
    "datasets_2 = cf.load_and_preprocess_datasets(months, data_path, '2min', filter)\n",
    "\n",
    "# Create training and test sets\n",
    "dt_train = pd.concat([datasets_2['dtf'+month[1:]] for month in months_train])\n",
    "dt_test = pd.concat([datasets_2['dtf'+month[1:]] for month in months_test])\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X_train = dt_train.iloc[:, :-1].values\n",
    "y_train = dt_train.iloc[:, -1].values\n",
    "X_test = dt_test.iloc[:, :-1].values\n",
    "y_test = dt_test.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender and simplay\n",
    "X_train[:, 0] = le.fit_transform(X_train[:, 0])\n",
    "X_train[:, 1] = le.fit_transform(X_train[:, 1])\n",
    "X_test[:, 0] = le.fit_transform(X_test[:, 0])\n",
    "X_test[:, 1] = le.fit_transform(X_test[:, 1])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [2, 3, 6])], remainder='passthrough')\n",
    "X_train = np.array(ct.fit_transform(X_train))\n",
    "X_test = np.array(ct.transform(X_test))\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# # Feature Scaling\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred))\n",
    "\n",
    "# Interpretation of confusion matrix\n",
    "print('True Positive (B20): ', cm[0][0])\n",
    "print('True Negative (T20): ', cm[1][1])\n",
    "print('False Positive: ', cm[0][1])\n",
    "print('False Negative: ', cm[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1747  454]\n",
      " [ 629 1689]]\n",
      "Accuracy:  0.7603452091170613\n",
      "Precision:  0.7881474568362109\n",
      "Recall:  0.7286453839516824\n",
      "F1 Score:  0.7572293207800942\n",
      "True Positive (B20):  1747\n",
      "True Negative (T20):  1689\n",
      "False Positive:  454\n",
      "False Negative:  629\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets for 3min, named it datasets_3\n",
    "datasets_3 = cf.load_and_preprocess_datasets(months, data_path, '3min', filter)\n",
    "\n",
    "# Create training and test sets\n",
    "dt_train = pd.concat([datasets_3['dtf'+month[1:]] for month in months_train])\n",
    "dt_test = pd.concat([datasets_3['dtf'+month[1:]] for month in months_test])\n",
    "\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X_train = dt_train.iloc[:, :-1].values\n",
    "y_train = dt_train.iloc[:, -1].values\n",
    "X_test = dt_test.iloc[:, :-1].values\n",
    "y_test = dt_test.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender and simplay\n",
    "X_train[:, 0] = le.fit_transform(X_train[:, 0])\n",
    "X_train[:, 1] = le.fit_transform(X_train[:, 1])\n",
    "X_test[:, 0] = le.fit_transform(X_test[:, 0])\n",
    "X_test[:, 1] = le.fit_transform(X_test[:, 1])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [2, 3, 6])], remainder='passthrough')\n",
    "X_train = np.array(ct.fit_transform(X_train))\n",
    "X_test = np.array(ct.transform(X_test))\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# # Feature Scaling\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred))\n",
    "\n",
    "# Interpretation of confusion matrix\n",
    "print('True Positive (B20): ', cm[0][0])\n",
    "print('True Negative (T20): ', cm[1][1])\n",
    "print('False Positive: ', cm[0][1])\n",
    "print('False Negative: ', cm[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1844  357]\n",
      " [ 566 1752]]\n",
      "Accuracy:  0.7957512724053994\n",
      "Precision:  0.8307254623044097\n",
      "Recall:  0.7558239861949957\n",
      "F1 Score:  0.7915066636548453\n",
      "True Positive (B20):  1844\n",
      "True Negative (T20):  1752\n",
      "False Positive:  357\n",
      "False Negative:  566\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets for 4min, named it datasets_4\n",
    "datasets_4 = cf.load_and_preprocess_datasets(months, data_path, '4min', filter)\n",
    "\n",
    "# Create training and test sets\n",
    "dt_train = pd.concat([datasets_4['dtf'+month[1:]] for month in months_train])\n",
    "dt_test = pd.concat([datasets_4['dtf'+month[1:]] for month in months_test])\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X_train = dt_train.iloc[:, :-1].values\n",
    "y_train = dt_train.iloc[:, -1].values\n",
    "X_test = dt_test.iloc[:, :-1].values\n",
    "y_test = dt_test.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender and simplay\n",
    "X_train[:, 0] = le.fit_transform(X_train[:, 0])\n",
    "X_train[:, 1] = le.fit_transform(X_train[:, 1])\n",
    "X_test[:, 0] = le.fit_transform(X_test[:, 0])\n",
    "X_test[:, 1] = le.fit_transform(X_test[:, 1])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [2, 3, 6])], remainder='passthrough')\n",
    "X_train = np.array(ct.fit_transform(X_train))\n",
    "X_test = np.array(ct.transform(X_test))\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# # Feature Scaling\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred))\n",
    "\n",
    "# Interpretation of confusion matrix\n",
    "print('True Positive (B20): ', cm[0][0])\n",
    "print('True Negative (T20): ', cm[1][1])\n",
    "print('False Positive: ', cm[0][1])\n",
    "print('False Negative: ', cm[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remainder__x10: 0.06766711072799939\n",
      "remainder__x33: 0.06727529190502311\n",
      "remainder__x54: 0.060003134550583814\n",
      "remainder__x26: 0.046924222239636396\n",
      "remainder__x32: 0.037857534675965844\n",
      "remainder__x9: 0.03649400517200848\n",
      "encoder__x2_Millenials: 0.035193166679727286\n",
      "remainder__x49: 0.03239558028367684\n",
      "remainder__x50: 0.019308831596269893\n",
      "remainder__x36: 0.01807852049212442\n",
      "remainder__x34: 0.01774155630436487\n",
      "remainder__x37: 0.017435937622443397\n",
      "remainder__x51: 0.017028446046548084\n",
      "remainder__x25: 0.016722827364626623\n",
      "remainder__x24: 0.016244808400595567\n",
      "remainder__x27: 0.015641407413212127\n",
      "encoder__x2_Baby Boomers: 0.015124206566883458\n",
      "remainder__x11: 0.014505132826580992\n",
      "remainder__x18: 0.014465950944283356\n",
      "remainder__x23: 0.014066295744847579\n",
      "remainder__x17: 0.01158216440717813\n",
      "remainder__x38: 0.011535146148420983\n",
      "remainder__x16: 0.010900399655199433\n",
      "remainder__x35: 0.007914740224120387\n",
      "remainder__x39: 0.007295666483817909\n",
      "remainder__x19: 0.0072564846015202526\n",
      "remainder__x7: 0.00698221142543688\n",
      "remainder__x21: 0.006206410155943909\n",
      "remainder__x20: 0.006206410155943887\n",
      "remainder__x12: 0.00565786380377713\n",
      "remainder__x8: 0.005250372227881828\n",
      "remainder__x4: 0.005046626439934187\n",
      "remainder__x22: 0.00416111590000785\n",
      "remainder__x14: 0.0034715147715696283\n",
      "encoder__x2_Gen X: 0.003267768983621977\n",
      "remainder__x53: 0.003087532325052911\n",
      "remainder__x5: 0.0029699866781600416\n",
      "remainder__x0: 0.00224904004388371\n",
      "remainder__x52: 0.0021706762792884637\n",
      "remainder__x15: 0.002155003526369381\n",
      "remainder__x41: 0.0019590941148812657\n",
      "remainder__x42: 0.0018180393386098225\n",
      "encoder__x6_gain: 0.0015594389154455102\n",
      "encoder__x6_loss: 0.001418384139174067\n",
      "encoder__x3_loss: 0.0012459838570645255\n",
      "encoder__x3_near-hit: 0.0011989655983073778\n",
      "remainder__x40: 0.0009873834339002019\n",
      "encoder__x2_Silent: 0.0008071467753311135\n",
      "remainder__x13: 0.0006974375048977244\n",
      "encoder__x6_near-hit: 0.0005877282344643686\n",
      "encoder__x3_draw: 0.00043883708173337866\n",
      "remainder__x31: 0.00043883708173337866\n",
      "remainder__x44: 0.00043100070527385403\n",
      "encoder__x2_Gen Z: 0.00035263694067860785\n",
      "remainder__x28: 0.0002899459290024109\n",
      "remainder__x45: 0.00015672752919049238\n",
      "encoder__x3_gain: 0.00014105477627144314\n",
      "remainder__x1: 0.00010187289397382005\n",
      "encoder__x6_draw: 8.62001410547708e-05\n",
      "remainder__x43: 8.62001410547708e-05\n",
      "remainder__x48: 7.836376459524619e-05\n",
      "remainder__x30: 7.052738813572157e-05\n",
      "remainder__x29: 0.0\n",
      "remainder__x46: 0.0\n",
      "remainder__x47: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(classifier, X_train, y_train, n_repeats=10, random_state=42)\n",
    "\n",
    "# Get feature importances and feature names\n",
    "importances = result.importances_mean\n",
    "feature_names = ct.get_feature_names_out()\n",
    "\n",
    "# Sort feature importances\n",
    "feature_importance = list(zip(feature_names, importances))\n",
    "feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print feature importances\n",
    "for feature, importance in feature_importance:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1934  267]\n",
      " [ 530 1788]]\n",
      "Accuracy:  0.8236335472449657\n",
      "Precision:  0.8700729927007299\n",
      "Recall:  0.7713546160483176\n",
      "F1 Score:  0.8177452549737023\n",
      "True Positive (B20):  1934\n",
      "True Negative (T20):  1788\n",
      "False Positive:  267\n",
      "False Negative:  530\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets for 5min, named it datasets_5\n",
    "datasets_5 = cf.load_and_preprocess_datasets(months, data_path, '5min', filter)\n",
    "\n",
    "# Create training and test sets\n",
    "dt_train = pd.concat([datasets_5['dtf'+month[1:]] for month in months_train])\n",
    "dt_test = pd.concat([datasets_5['dtf'+month[1:]] for month in months_test])\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X_train = dt_train.iloc[:, :-1].values\n",
    "y_train = dt_train.iloc[:, -1].values\n",
    "X_test = dt_test.iloc[:, :-1].values\n",
    "y_test = dt_test.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender and simplay\n",
    "X_train[:, 0] = le.fit_transform(X_train[:, 0])\n",
    "X_train[:, 1] = le.fit_transform(X_train[:, 1])\n",
    "X_test[:, 0] = le.fit_transform(X_test[:, 0])\n",
    "X_test[:, 1] = le.fit_transform(X_test[:, 1])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [2, 3, 6])], remainder='passthrough')\n",
    "X_train = np.array(ct.fit_transform(X_train))\n",
    "X_test = np.array(ct.transform(X_test))\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# # Feature Scaling\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred))\n",
    "\n",
    "# Interpretation of confusion matrix\n",
    "print('True Positive (B20): ', cm[0][0])\n",
    "print('True Negative (T20): ', cm[1][1])\n",
    "print('False Positive: ', cm[0][1])\n",
    "print('False Negative: ', cm[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remainder__x33: 0.07348170206096707\n",
      "remainder__x54: 0.07329362902593846\n",
      "remainder__x10: 0.04490243711307897\n",
      "remainder__x26: 0.044236345114019325\n",
      "remainder__x9: 0.037066060653553834\n",
      "remainder__x32: 0.031204451061829064\n",
      "encoder__x2_Millenials: 0.028257973513047607\n",
      "remainder__x34: 0.019779014183841447\n",
      "remainder__x49: 0.018517357573857907\n",
      "remainder__x51: 0.017294882846171988\n",
      "remainder__x25: 0.016095917247864643\n",
      "remainder__x11: 0.014418932685526287\n",
      "remainder__x27: 0.014387587179688166\n",
      "remainder__x36: 0.014285714285714346\n",
      "remainder__x23: 0.014027113862549989\n",
      "encoder__x2_Baby Boomers: 0.013462894757464205\n",
      "remainder__x24: 0.013345349110571336\n",
      "remainder__x50: 0.012585220593997382\n",
      "remainder__x16: 0.011182509207742386\n",
      "remainder__x37: 0.010626126479116116\n",
      "remainder__x18: 0.009897343468380271\n",
      "remainder__x38: 0.007703158059713245\n",
      "remainder__x19: 0.007256484601520308\n",
      "remainder__x17: 0.0070370660606535965\n",
      "remainder__x21: 0.006786302013948797\n",
      "remainder__x40: 0.006598228978920184\n",
      "remainder__x4: 0.006253428414701079\n",
      "remainder__x35: 0.005454118015829535\n",
      "remainder__x22: 0.0052817177337199815\n",
      "remainder__x20: 0.005015280934096112\n",
      "remainder__x52: 0.004882062534284193\n",
      "remainder__x39: 0.004764516887391301\n",
      "remainder__x12: 0.004756680510931777\n",
      "remainder__x8: 0.004247316041062677\n",
      "remainder__x7: 0.0038946791003840464\n",
      "remainder__x5: 0.0030483504427552986\n",
      "remainder__x53: 0.003024841313376725\n",
      "remainder__x41: 0.0024762949612100018\n",
      "remainder__x15: 0.0022098581615861423\n",
      "remainder__x14: 0.0021079852676123335\n",
      "remainder__x0: 0.0020374578794766117\n",
      "encoder__x2_Gen X: 0.0018885667267456107\n",
      "remainder__x42: 0.001441893268552652\n",
      "encoder__x3_near-hit: 0.0011597837160097547\n",
      "encoder__x6_gain: 0.0008620014105478191\n",
      "encoder__x2_Gen Z: 0.0008149831517906714\n",
      "encoder__x6_loss: 0.0007366193871954252\n",
      "encoder__x3_loss: 0.0006817647519787529\n",
      "encoder__x6_near-hit: 0.0006660919990597036\n",
      "remainder__x13: 0.0006112373638430313\n",
      "encoder__x3_gain: 0.0005877282344644574\n",
      "remainder__x44: 0.0004858553404906374\n",
      "encoder__x2_Silent: 0.0004545098346525389\n",
      "encoder__x3_draw: 0.00028994592900252194\n",
      "remainder__x31: 0.00017240028210965263\n",
      "remainder__x29: 0.00016456390565012803\n",
      "remainder__x45: 0.00011754564689294699\n",
      "remainder__x30: 0.00010187289397390886\n",
      "remainder__x48: 7.05273881358215e-05\n",
      "remainder__x43: 2.3509129378618267e-05\n",
      "remainder__x28: 2.3509129378607164e-05\n",
      "remainder__x46: 0.0\n",
      "remainder__x47: 0.0\n",
      "encoder__x6_draw: -7.836376459502414e-06\n",
      "remainder__x1: -2.3509129378573855e-05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(classifier, X_train, y_train, n_repeats=10, random_state=42)\n",
    "\n",
    "# Get feature importances and feature names\n",
    "importances = result.importances_mean\n",
    "feature_names = ct.get_feature_names_out()\n",
    "\n",
    "# Sort feature importances\n",
    "feature_importance = list(zip(feature_names, importances))\n",
    "feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print feature importances\n",
    "for feature, importance in feature_importance:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2117   84]\n",
      " [ 395 1923]]\n",
      "Accuracy:  0.8940030980305377\n",
      "Precision:  0.9581464872944694\n",
      "Recall:  0.8295944779982743\n",
      "F1 Score:  0.8892485549132947\n",
      "True Positive (B20):  2117\n",
      "True Negative (T20):  1923\n",
      "False Positive:  84\n",
      "False Negative:  395\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets for 10min, named it datasets_10\n",
    "datasets_10 = cf.load_and_preprocess_datasets(months, data_path, '10min', filter)\n",
    "\n",
    "# Create training and test sets\n",
    "dt_train = pd.concat([datasets_10['dtf'+month[1:]] for month in months_train])\n",
    "dt_test = pd.concat([datasets_10['dtf'+month[1:]] for month in months_test])\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X_train = dt_train.iloc[:, :-1].values\n",
    "y_train = dt_train.iloc[:, -1].values\n",
    "X_test = dt_test.iloc[:, :-1].values\n",
    "y_test = dt_test.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender and simplay\n",
    "X_train[:, 0] = le.fit_transform(X_train[:, 0])\n",
    "X_train[:, 1] = le.fit_transform(X_train[:, 1])\n",
    "X_test[:, 0] = le.fit_transform(X_test[:, 0])\n",
    "X_test[:, 1] = le.fit_transform(X_test[:, 1])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [2, 3, 6])], remainder='passthrough')\n",
    "X_train = np.array(ct.fit_transform(X_train))\n",
    "X_test = np.array(ct.transform(X_test))\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# # Feature Scaling\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred))\n",
    "\n",
    "# Interpretation of confusion matrix\n",
    "print('True Positive (B20): ', cm[0][0])\n",
    "print('True Negative (T20): ', cm[1][1])\n",
    "print('False Positive: ', cm[0][1])\n",
    "print('False Negative: ', cm[1][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2165   36]\n",
      " [ 348 1970]]\n",
      "Accuracy:  0.9150254481079885\n",
      "Precision:  0.9820538384845464\n",
      "Recall:  0.8498705780845557\n",
      "F1 Score:  0.9111933395004626\n",
      "True Positive (B20):  2165\n",
      "True Negative (T20):  1970\n",
      "False Positive:  36\n",
      "False Negative:  348\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets for 15min, named it datasets_15\n",
    "datasets_15 = cf.load_and_preprocess_datasets(months, data_path, '15min', filter)\n",
    "\n",
    "# Create training and test sets\n",
    "dt_train = pd.concat([datasets_15['dtf'+month[1:]] for month in months_train])\n",
    "dt_test = pd.concat([datasets_15['dtf'+month[1:]] for month in months_test])\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X_train = dt_train.iloc[:, :-1].values\n",
    "y_train = dt_train.iloc[:, -1].values\n",
    "X_test = dt_test.iloc[:, :-1].values\n",
    "y_test = dt_test.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender and simplay\n",
    "X_train[:, 0] = le.fit_transform(X_train[:, 0])\n",
    "X_train[:, 1] = le.fit_transform(X_train[:, 1])\n",
    "X_test[:, 0] = le.fit_transform(X_test[:, 0])\n",
    "X_test[:, 1] = le.fit_transform(X_test[:, 1])\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [2, 3, 6])], remainder='passthrough')\n",
    "X_train = np.array(ct.fit_transform(X_train))\n",
    "X_test = np.array(ct.transform(X_test))\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# # Feature Scaling\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred))\n",
    "\n",
    "# Interpretation of confusion matrix\n",
    "print('True Positive (B20): ', cm[0][0])\n",
    "print('True Negative (T20): ', cm[1][1])\n",
    "print('False Positive: ', cm[0][1])\n",
    "print('False Negative: ', cm[1][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
