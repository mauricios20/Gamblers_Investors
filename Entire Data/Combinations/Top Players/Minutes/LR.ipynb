{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "import counting_fns as cf\n",
    "\n",
    "\n",
    "# List of all the months\n",
    "months = ['2_June', '3_July', '4_August', '5_September', '6_October']\n",
    "\n",
    "# Define the path to the data directory and columns to keep\n",
    "data_path = \"/Users/mau/Library/CloudStorage/Dropbox/Mac/Documents/Dissertation/Chapter 2/Entire_Data/By month\"\n",
    "\n",
    "# Filter Desire Columns\n",
    "filter = ['session_time', 'gender', 'age_gen', 'first_outcome',\n",
    "        'first_wager','first_p/b', 'last_outcome', 'last_wager', 'last_p/b',\n",
    "        'beginning_amt', 'ending_amt', 'ending_balance', 'ave_slotdenom', \n",
    "        'std_slotdenom', 'min_slotdenom', 'max_slotdenom', 'ave_theo_payback',\n",
    "        'min_theo_payback', 'max_theo_payback', 'ave_wageramt', 'std_wageramt',\n",
    "        'min_wager', 'max_wager', 'ave_p/b', 'std_p/b', 'max_p/b', 'max_profit', 'depletion_slope', \n",
    "        '#inc_slotdenom', '#dec_slotdenom', '#inc_maxbet', '#dec_maxbet', \n",
    "        '#W', '#L', '#NH', '#D','w/g', 'l/g', 'nh/g', 'd/g', '#2ws', '2ws_profit', '2ws_wgramt', '#3ws',\n",
    "        '3ws_profit', '3ws_wgramt', '#4ws', '4ws_profit', '4ws_wgramt','ave_time_per_gamble', \n",
    "        'min_time_per_gamble', 'max_time_per_gamble',\n",
    "        'machines_changes', 'unique_machines',  'ave_time_per_machine', 'classification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Months in training set: ['3_July', '5_September', '2_June', '6_October']\n",
      "Months in test set: ['4_August']\n"
     ]
    }
   ],
   "source": [
    "# Randomly select 3 months for training set\n",
    "# random.seed(350)\n",
    "months_train = random.sample(months, 4)\n",
    "\n",
    "# Print the months in the training set\n",
    "print(\"Months in training set:\", months_train)\n",
    "\n",
    "# Create a list of remaining months for the test set\n",
    "months_test = [month for month in months if month not in months_train]\n",
    "# Print the months in the test set\n",
    "print(\"Months in test set:\", months_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataframes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1485  413  480  555]\n",
      " [1046  415  642  827]\n",
      " [ 872  348  709 1024]\n",
      " [ 583  223  497 1508]]\n",
      "Accuracy:  0.35408961899028124\n",
      "Precision:  0.3397578145507635\n",
      "Recall:  0.3561261177212172\n",
      "F1 Score:  0.33449214057407434\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "datasets = cf.load_and_preprocess_datasets_min_all(months, data_path, '1min', filter)\n",
    "\n",
    "# Create training and test sets\n",
    "dt_train = pd.concat([datasets['dtf'+month[1:]] for month in months_train])\n",
    "dt_test = pd.concat([datasets['dtf'+month[1:]] for month in months_test])\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X_train = dt_train.iloc[:, :-1].values\n",
    "y_train = dt_train.iloc[:, -1].values\n",
    "X_test = dt_test.iloc[:, :-1].values\n",
    "y_test = dt_test.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X_train[:, 0] = le.fit_transform(X_train[:, 0])\n",
    "X_test[:, 0] = le.fit_transform(X_test[:, 0])\n",
    "\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 5])], remainder='passthrough')\n",
    "X_train = np.array(ct.fit_transform(X_train))\n",
    "X_test = np.array(ct.transform(X_test))\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# # Feature Scaling\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0, max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1507  422  540  464]\n",
      " [1054  427  747  702]\n",
      " [ 864  380  829  880]\n",
      " [ 473  202  631 1505]]\n",
      "Accuracy:  0.36707663197729423\n",
      "Precision:  0.35265232212543757\n",
      "Recall:  0.3689175728099079\n",
      "F1 Score:  0.3502623326577189\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets for 2min, named it datasets_2\n",
    "datasets_2 = cf.load_and_preprocess_datasets_min_all(months, data_path, '2min', filter)\n",
    "\n",
    "# Create training and test sets\n",
    "dt_train = pd.concat([datasets_2['dtf'+month[1:]] for month in months_train])\n",
    "dt_test = pd.concat([datasets_2['dtf'+month[1:]] for month in months_test])\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X_train = dt_train.iloc[:, :-1].values\n",
    "y_train = dt_train.iloc[:, -1].values\n",
    "X_test = dt_test.iloc[:, :-1].values\n",
    "y_test = dt_test.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X_train[:, 0] = le.fit_transform(X_train[:, 0])\n",
    "X_test[:, 0] = le.fit_transform(X_test[:, 0])\n",
    "\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 5])], remainder='passthrough')\n",
    "X_train = np.array(ct.fit_transform(X_train))\n",
    "X_test = np.array(ct.transform(X_test))\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# # Feature Scaling\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0, max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1514  419  581  419]\n",
      " [1068  478  784  600]\n",
      " [ 830  465  903  755]\n",
      " [ 368  204  628 1611]]\n",
      "Accuracy:  0.38754622860583127\n",
      "Precision:  0.37337448852358374\n",
      "Recall:  0.38955783288816237\n",
      "F1 Score:  0.37312054778108406\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets for 3min, named it datasets_3\n",
    "datasets_3 = cf.load_and_preprocess_datasets_min_all(months, data_path, '3min', filter)\n",
    "\n",
    "# Create training and test sets\n",
    "dt_train = pd.concat([datasets_3['dtf'+month[1:]] for month in months_train])\n",
    "dt_test = pd.concat([datasets_3['dtf'+month[1:]] for month in months_test])\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X_train = dt_train.iloc[:, :-1].values\n",
    "y_train = dt_train.iloc[:, -1].values\n",
    "X_test = dt_test.iloc[:, :-1].values\n",
    "y_test = dt_test.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X_train[:, 0] = le.fit_transform(X_train[:, 0])\n",
    "X_test[:, 0] = le.fit_transform(X_test[:, 0])\n",
    "\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 5])], remainder='passthrough')\n",
    "X_train = np.array(ct.fit_transform(X_train))\n",
    "X_test = np.array(ct.transform(X_test))\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# # Feature Scaling\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0, max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1507  393  616  417]\n",
      " [1049  434  841  606]\n",
      " [ 824  396  954  779]\n",
      " [ 308  150  579 1774]]\n",
      "Accuracy:  0.4015653220951234\n",
      "Precision:  0.3849668139572198\n",
      "Recall:  0.40402117145995964\n",
      "F1 Score:  0.3833728290928945\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets for 4min, named it datasets_4\n",
    "datasets_4 = cf.load_and_preprocess_datasets_min_all(months, data_path, '4min', filter)\n",
    "\n",
    "# Create training and test sets\n",
    "dt_train = pd.concat([datasets_4['dtf'+month[1:]] for month in months_train])\n",
    "dt_test = pd.concat([datasets_4['dtf'+month[1:]] for month in months_test])\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X_train = dt_train.iloc[:, :-1].values\n",
    "y_train = dt_train.iloc[:, -1].values\n",
    "X_test = dt_test.iloc[:, :-1].values\n",
    "y_test = dt_test.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X_train[:, 0] = le.fit_transform(X_train[:, 0])\n",
    "X_test[:, 0] = le.fit_transform(X_test[:, 0])\n",
    "\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 5])], remainder='passthrough')\n",
    "X_train = np.array(ct.fit_transform(X_train))\n",
    "X_test = np.array(ct.transform(X_test))\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# # Feature Scaling\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0, max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1512  410  570  441]\n",
      " [1030  493  790  617]\n",
      " [ 810  403  964  776]\n",
      " [ 251  125  538 1897]]\n",
      "Accuracy:  0.4185086436742066\n",
      "Precision:  0.4023586968092103\n",
      "Recall:  0.4212672501838899\n",
      "F1 Score:  0.4000661304569735\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets for 5min, named it datasets_5\n",
    "datasets_5 = cf.load_and_preprocess_datasets_min_all(months, data_path, '5min', filter)\n",
    "\n",
    "# Create training and test sets\n",
    "dt_train = pd.concat([datasets_5['dtf'+month[1:]] for month in months_train])\n",
    "dt_test = pd.concat([datasets_5['dtf'+month[1:]] for month in months_test])\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X_train = dt_train.iloc[:, :-1].values\n",
    "y_train = dt_train.iloc[:, -1].values\n",
    "X_test = dt_test.iloc[:, :-1].values\n",
    "y_test = dt_test.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X_train[:, 0] = le.fit_transform(X_train[:, 0])\n",
    "X_test[:, 0] = le.fit_transform(X_test[:, 0])\n",
    "\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 5])], remainder='passthrough')\n",
    "X_train = np.array(ct.fit_transform(X_train))\n",
    "X_test = np.array(ct.transform(X_test))\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# # Feature Scaling\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0, max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
