{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Support Vector Machine (SVM) Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "import random\n",
    "import counting_fns as cf\n",
    "\n",
    "# List of all the months\n",
    "months = ['2_June', '3_July', '4_August', '5_September', '6_October']\n",
    "\n",
    "# Define the path to the data directory and columns to keep\n",
    "data_path = \"/Users/mau/Library/CloudStorage/Dropbox/Mac/Documents/Dissertation/Chapter 2/Entire_Data/By month\"\n",
    "\n",
    "# Filter Desire Columns\n",
    "filter = ['session_time', 'gender', 'age_gen', 'first_outcome',\n",
    "        'first_wager','first_p/b', 'last_outcome', 'last_wager', 'last_p/b',\n",
    "        'beginning_amt', 'ending_amt', 'ending_balance', 'ave_slotdenom', \n",
    "        'std_slotdenom', 'min_slotdenom', 'max_slotdenom', 'ave_theo_payback',\n",
    "        'min_theo_payback', 'max_theo_payback', 'ave_wageramt', 'std_wageramt',\n",
    "        'min_wager', 'max_wager', 'ave_p/b', 'std_p/b', 'max_p/b', 'max_profit', 'depletion_slope', \n",
    "        '#inc_slotdenom', '#dec_slotdenom', '#inc_maxbet', '#dec_maxbet', \n",
    "        '#W', '#L', '#NH', '#D','w/g', 'l/g', 'nh/g', 'd/g', '#2ws', '2ws_profit', '2ws_wgramt', '#3ws',\n",
    "        '3ws_profit', '3ws_wgramt', '#4ws', '4ws_profit', '4ws_wgramt','ave_time_per_gamble', \n",
    "        'min_time_per_gamble', 'max_time_per_gamble',\n",
    "        'machines_changes', 'unique_machines',  'ave_time_per_machine', 'classification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Months in training set: ['4_August', '6_October', '3_July', '2_June']\n",
      "Months in test set: ['5_September']\n"
     ]
    }
   ],
   "source": [
    "# Randomly select 3 months for training set\n",
    "# random.seed(350)\n",
    "months_train = random.sample(months, 4)\n",
    "\n",
    "# Print the months in the training set\n",
    "print(\"Months in training set:\", months_train)\n",
    "\n",
    "# Create a list of remaining months for the test set\n",
    "months_test = [month for month in months if month not in months_train]\n",
    "# Print the months in the test set\n",
    "print(\"Months in test set:\", months_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataframes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1257  572  553  355]\n",
      " [ 890  574  744  487]\n",
      " [ 735  588  833  568]\n",
      " [ 428  435  686 1012]]\n",
      "Accuracy:  0.3430064383689465\n",
      "Precision:  0.33951063701870776\n",
      "Recall:  0.3433018534199079\n",
      "F1 Score:  0.339666529440535\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "datasets = cf.load_and_preprocess_datasets_min_all(months, data_path, '1min', filter)\n",
    "\n",
    "# Create training and test sets\n",
    "dt_train = pd.concat([datasets['dtf'+month[1:]] for month in months_train])\n",
    "dt_test = pd.concat([datasets['dtf'+month[1:]] for month in months_test])\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X_train = dt_train.iloc[:, :-1].values\n",
    "y_train = dt_train.iloc[:, -1].values\n",
    "X_test = dt_test.iloc[:, :-1].values\n",
    "y_test = dt_test.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X_train[:, 0] = le.fit_transform(X_train[:, 0])\n",
    "X_test[:, 0] = le.fit_transform(X_test[:, 0])\n",
    "\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 5])], remainder='passthrough')\n",
    "X_train = np.array(ct.fit_transform(X_train))\n",
    "X_test = np.array(ct.transform(X_test))\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# # Feature Scaling\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1303  581  484  369]\n",
      " [ 864  615  712  504]\n",
      " [ 710  616  824  574]\n",
      " [ 360  370  603 1228]]\n",
      "Accuracy:  0.3704394886628721\n",
      "Precision:  0.3643985631236958\n",
      "Recall:  0.371566395891675\n",
      "F1 Score:  0.36642460560245727\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets for 2min, named it datasets_2\n",
    "datasets_2 = cf.load_and_preprocess_datasets_min_all(months, data_path, '2min', filter)\n",
    "\n",
    "# Create training and test sets\n",
    "dt_train = pd.concat([datasets_2['dtf'+month[1:]] for month in months_train])\n",
    "dt_test = pd.concat([datasets_2['dtf'+month[1:]] for month in months_test])\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X_train = dt_train.iloc[:, :-1].values\n",
    "y_train = dt_train.iloc[:, -1].values\n",
    "X_test = dt_test.iloc[:, :-1].values\n",
    "y_test = dt_test.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X_train[:, 0] = le.fit_transform(X_train[:, 0])\n",
    "X_test[:, 0] = le.fit_transform(X_test[:, 0])\n",
    "\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 5])], remainder='passthrough')\n",
    "X_train = np.array(ct.fit_transform(X_train))\n",
    "X_test = np.array(ct.transform(X_test))\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# # Feature Scaling\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1293  559  489  396]\n",
      " [ 873  582  730  510]\n",
      " [ 697  586  827  614]\n",
      " [ 266  277  596 1422]]\n",
      "Accuracy:  0.38480918167397593\n",
      "Precision:  0.3750038321174903\n",
      "Recall:  0.3868050078335584\n",
      "F1 Score:  0.3784009727962735\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets for 3min, named it datasets_3\n",
    "datasets_3 = cf.load_and_preprocess_datasets_min_all(months, data_path, '3min', filter)\n",
    "\n",
    "# Create training and test sets\n",
    "dt_train = pd.concat([datasets_3['dtf'+month[1:]] for month in months_train])\n",
    "dt_test = pd.concat([datasets_3['dtf'+month[1:]] for month in months_test])\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X_train = dt_train.iloc[:, :-1].values\n",
    "y_train = dt_train.iloc[:, -1].values\n",
    "X_test = dt_test.iloc[:, :-1].values\n",
    "y_test = dt_test.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X_train[:, 0] = le.fit_transform(X_train[:, 0])\n",
    "X_test[:, 0] = le.fit_transform(X_test[:, 0])\n",
    "\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 5])], remainder='passthrough')\n",
    "X_train = np.array(ct.fit_transform(X_train))\n",
    "X_test = np.array(ct.transform(X_test))\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# # Feature Scaling\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1250  585  480  422]\n",
      " [ 850  598  731  516]\n",
      " [ 639  602  849  634]\n",
      " [ 200  212  506 1643]]\n",
      "Accuracy:  0.40496407576747223\n",
      "Precision:  0.39166776427837263\n",
      "Recall:  0.40795427350455676\n",
      "F1 Score:  0.39631044664317133\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets for 4min, named it datasets_4\n",
    "datasets_4 = cf.load_and_preprocess_datasets_min_all(months, data_path, '4min', filter)\n",
    "\n",
    "# Create training and test sets\n",
    "dt_train = pd.concat([datasets_4['dtf'+month[1:]] for month in months_train])\n",
    "dt_test = pd.concat([datasets_4['dtf'+month[1:]] for month in months_test])\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X_train = dt_train.iloc[:, :-1].values\n",
    "y_train = dt_train.iloc[:, -1].values\n",
    "X_test = dt_test.iloc[:, :-1].values\n",
    "y_test = dt_test.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X_train[:, 0] = le.fit_transform(X_train[:, 0])\n",
    "X_test[:, 0] = le.fit_transform(X_test[:, 0])\n",
    "\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 5])], remainder='passthrough')\n",
    "X_train = np.array(ct.fit_transform(X_train))\n",
    "X_test = np.array(ct.transform(X_test))\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# # Feature Scaling\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1275  514  520  428]\n",
      " [ 836  553  768  538]\n",
      " [ 628  513  891  692]\n",
      " [ 148  144  439 1830]]\n",
      "Accuracy:  0.4244658019968275\n",
      "Precision:  0.4068481685365636\n",
      "Recall:  0.42817261217971403\n",
      "F1 Score:  0.4105846062030703\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets for 5min, named it datasets_5\n",
    "datasets_5 = cf.load_and_preprocess_datasets_min_all(months, data_path, '5min', filter)\n",
    "\n",
    "# Create training and test sets\n",
    "dt_train = pd.concat([datasets_5['dtf'+month[1:]] for month in months_train])\n",
    "dt_test = pd.concat([datasets_5['dtf'+month[1:]] for month in months_test])\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X_train = dt_train.iloc[:, :-1].values\n",
    "y_train = dt_train.iloc[:, -1].values\n",
    "X_test = dt_test.iloc[:, :-1].values\n",
    "y_test = dt_test.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X_train[:, 0] = le.fit_transform(X_train[:, 0])\n",
    "X_test[:, 0] = le.fit_transform(X_test[:, 0])\n",
    "\n",
    "\n",
    "# # Encode age_generartion, first_outoce, last_outcome columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 5])], remainder='passthrough')\n",
    "X_train = np.array(ct.fit_transform(X_train))\n",
    "X_test = np.array(ct.transform(X_test))\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# # Feature Scaling\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Scale all columns except the encoded ones\n",
    "X_train[:, 14:] = sc.fit_transform(X_train[:, 14:])\n",
    "X_test[:, 14:] = sc.transform(X_test[:, 14:])\n",
    "\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
