{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import counting_fns as cf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# List of all the months\n",
    "months = ['2_June', '3_July', '4_August', '5_September', '6_October']\n",
    "\n",
    "# Define the path to the data directory and columns to keep\n",
    "data_path = \"/Users/mau/Library/CloudStorage/Dropbox/Mac/Documents/Dissertation/Chapter 2/Entire_Data/By month\"\n",
    "\n",
    "# Filter Columns\n",
    "filter = ['session_time', 'gender', 'age_gen', 'day', 'timeofday', 'first_outcome',\n",
    "        'first_wager','first_p/b', 'last_outcome', 'last_wager', 'last_p/b',\n",
    "        'beginning_amt', 'ending_amt', 'ending_balance', 'ave_slotdenom', \n",
    "        'std_slotdenom', 'min_slotdenom', 'max_slotdenom', 'ave_theo_payback',\n",
    "        'min_theo_payback', 'max_theo_payback', 'ave_wageramt', 'std_wageramt',\n",
    "        'min_wager', 'max_wager', 'ave_p/b', 'std_p/b', 'max_p/b', 'max_profit', 'depletion_slope', \n",
    "        '#inc_slotdenom', '#dec_slotdenom', '#inc_maxbet', '#dec_maxbet', '#W', '#L', '#NH', '#D',\n",
    "        'w/min', 'l/min', '#2ws', '2ws_profit', '2ws_wgramt','2ws/min', \n",
    "        '#3ws', '3ws_profit', '3ws_wgramt', '3ws/min', '#4ws', '4ws_profit', '4ws_wgramt', '4ws/min', \n",
    "        'w/g', 'l/g', 'nh/g', 'd/g', 'ave_time_per_gamble', \n",
    "        'min_time_per_gamble', 'max_time_per_gamble', 'total_gambles',\n",
    "        'machines_changes', 'unique_machines', 'ave_time_per_machine', 'classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick best overall parameters\n",
    "best_params = {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gender', 'age_gen', 'day', 'timeofday', 'first_outcome', 'first_wager',\n",
      "       'first_p/b', 'last_outcome', 'last_wager', 'last_p/b', 'beginning_amt',\n",
      "       'ending_amt', 'ending_balance', 'ave_slotdenom', 'std_slotdenom',\n",
      "       'min_slotdenom', 'max_slotdenom', 'ave_theo_payback',\n",
      "       'min_theo_payback', 'max_theo_payback', 'ave_wageramt', 'std_wageramt',\n",
      "       'min_wager', 'max_wager', 'ave_p/b', 'std_p/b', 'max_p/b', 'max_profit',\n",
      "       'depletion_slope', '#inc_slotdenom', '#dec_slotdenom', '#inc_maxbet',\n",
      "       '#dec_maxbet', '#W', '#L', '#NH', '#D', 'w/min', 'l/min', '#2ws',\n",
      "       '2ws_profit', '2ws_wgramt', '2ws/min', '#3ws', '3ws_profit',\n",
      "       '3ws_wgramt', '3ws/min', '#4ws', '4ws_profit', '4ws_wgramt', '4ws/min',\n",
      "       'w/g', 'l/g', 'nh/g', 'd/g', 'ave_time_per_gamble',\n",
      "       'min_time_per_gamble', 'max_time_per_gamble', 'total_gambles',\n",
      "       'machines_changes', 'unique_machines', 'ave_time_per_machine',\n",
      "       'classification'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data_1min = cf.load_and_preprocess_datasets_min_ntop(months, data_path, '1min', filter)\n",
    "\n",
    "# Concat all dataframes on data_1min\n",
    "dataset = pd.concat(data_1min)\n",
    "\n",
    "print(dataset.columns)\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # # Encode age_generartion, first_outoce, last_outcome, time of day columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 3, 4, 7])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Initialize stratified k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "results= []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    # Scale all columns except the encoded ones\n",
    "    X_train[:, 19:] = sc.fit_transform(X_train[:, 19:])\n",
    "    X_test[:, 19:] = sc.transform(X_test[:, 19:])\n",
    "\n",
    "    ## Handling Class Imbalance \n",
    "    # Apply SMOTE - SMOTE generates synthetic samples for the minority class to balance the dataset:\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    classifier = RandomForestClassifier(random_state=0, **best_params)\n",
    "    classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics for this fold\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    precision_scores.append(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "    recall_scores.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# Calculate the average evaluation metrics over all folds\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "average_precision = np.mean(precision_scores)\n",
    "average_recall = np.mean(recall_scores)\n",
    "average_f1 = np.mean(f1_scores)\n",
    "\n",
    "# Append results for this time interval\n",
    "results.append([ '1 min', round(average_accuracy, 3), round(std_accuracy, 3), round(average_precision, 3), round(average_recall, 3), round(average_f1, 3)])\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "# columns = ['Time', 'Mean Accuracy', 'Acc. Std.', 'Mean Precision', 'Mean Recall', 'Mean F1 Score']\n",
    "# results_df_1min = pd.DataFrame(results_1min, columns=columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gender', 'age_gen', 'day', 'timeofday', 'first_outcome', 'first_wager',\n",
      "       'first_p/b', 'last_outcome', 'last_wager', 'last_p/b', 'beginning_amt',\n",
      "       'ending_amt', 'ending_balance', 'ave_slotdenom', 'std_slotdenom',\n",
      "       'min_slotdenom', 'max_slotdenom', 'ave_theo_payback',\n",
      "       'min_theo_payback', 'max_theo_payback', 'ave_wageramt', 'std_wageramt',\n",
      "       'min_wager', 'max_wager', 'ave_p/b', 'std_p/b', 'max_p/b', 'max_profit',\n",
      "       'depletion_slope', '#inc_slotdenom', '#dec_slotdenom', '#inc_maxbet',\n",
      "       '#dec_maxbet', '#W', '#L', '#NH', '#D', 'w/min', 'l/min', '#2ws',\n",
      "       '2ws_profit', '2ws_wgramt', '2ws/min', '#3ws', '3ws_profit',\n",
      "       '3ws_wgramt', '3ws/min', '#4ws', '4ws_profit', '4ws_wgramt', '4ws/min',\n",
      "       'w/g', 'l/g', 'nh/g', 'd/g', 'ave_time_per_gamble',\n",
      "       'min_time_per_gamble', 'max_time_per_gamble', 'total_gambles',\n",
      "       'machines_changes', 'unique_machines', 'ave_time_per_machine',\n",
      "       'classification'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mau/Library/CloudStorage/Dropbox/Mac/Documents/GitHub/Gamblers_Investors/Entire Data/Combinations/Tunning/Minutes 10SCV/Random Forest.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mau/Library/CloudStorage/Dropbox/Mac/Documents/GitHub/Gamblers_Investors/Entire%20Data/Combinations/Tunning/Minutes%2010SCV/Random%20Forest.ipynb#X25sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m X_train_resampled, y_train_resampled \u001b[39m=\u001b[39m smote\u001b[39m.\u001b[39mfit_resample(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mau/Library/CloudStorage/Dropbox/Mac/Documents/GitHub/Gamblers_Investors/Entire%20Data/Combinations/Tunning/Minutes%2010SCV/Random%20Forest.ipynb#X25sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m classifier \u001b[39m=\u001b[39m RandomForestClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbest_params)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mau/Library/CloudStorage/Dropbox/Mac/Documents/GitHub/Gamblers_Investors/Entire%20Data/Combinations/Tunning/Minutes%2010SCV/Random%20Forest.ipynb#X25sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m classifier\u001b[39m.\u001b[39;49mfit(X_train_resampled, y_train_resampled)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mau/Library/CloudStorage/Dropbox/Mac/Documents/GitHub/Gamblers_Investors/Entire%20Data/Combinations/Tunning/Minutes%2010SCV/Random%20Forest.ipynb#X25sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m y_pred \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mau/Library/CloudStorage/Dropbox/Mac/Documents/GitHub/Gamblers_Investors/Entire%20Data/Combinations/Tunning/Minutes%2010SCV/Random%20Forest.ipynb#X25sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# Calculate evaluation metrics for this fold\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    477\u001b[0m )(\n\u001b[1;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    479\u001b[0m         t,\n\u001b[1;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    481\u001b[0m         X,\n\u001b[1;32m    482\u001b[0m         y,\n\u001b[1;32m    483\u001b[0m         sample_weight,\n\u001b[1;32m    484\u001b[0m         i,\n\u001b[1;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    489\u001b[0m     )\n\u001b[1;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 184\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    890\u001b[0m         X,\n\u001b[1;32m    891\u001b[0m         y,\n\u001b[1;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/tree/_classes.py:235\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    233\u001b[0m y_encoded \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(y\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[1;32m    234\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_):\n\u001b[0;32m--> 235\u001b[0m     classes_k, y_encoded[:, k] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49munique(y[:, k], return_inverse\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    236\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mappend(classes_k)\n\u001b[1;32m    237\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_\u001b[39m.\u001b[39mappend(classes_k\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[1;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39;49mequal_nan)\n\u001b[1;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/lib/arraysetops.py:358\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    356\u001b[0m     ret \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (perm[mask],)\n\u001b[1;32m    357\u001b[0m \u001b[39mif\u001b[39;00m return_inverse:\n\u001b[0;32m--> 358\u001b[0m     imask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mcumsum(mask) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    359\u001b[0m     inv_idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(mask\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp)\n\u001b[1;32m    360\u001b[0m     inv_idx[perm] \u001b[39m=\u001b[39m imask\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mcumsum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2597\u001b[0m, in \u001b[0;36mcumsum\u001b[0;34m(a, axis, dtype, out)\u001b[0m\n\u001b[1;32m   2523\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_cumsum_dispatcher)\n\u001b[1;32m   2524\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcumsum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2525\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2526\u001b[0m \u001b[39m    Return the cumulative sum of the elements along a given axis.\u001b[39;00m\n\u001b[1;32m   2527\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2595\u001b[0m \n\u001b[1;32m   2596\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2597\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mcumsum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis\u001b[39m=\u001b[39;49maxis, dtype\u001b[39m=\u001b[39;49mdtype, out\u001b[39m=\u001b[39;49mout)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_5min = cf.load_and_preprocess_datasets_min_ntop(months, data_path, '5min', filter)\n",
    "\n",
    "# Concat all dataframes on data_1min\n",
    "dataset = pd.concat(data_5min)\n",
    "\n",
    "print(dataset.columns)\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # # Encode age_generartion, first_outoce, last_outcome, time of day columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 3, 4, 7])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Initialize stratified k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    # Scale all columns except the encoded ones\n",
    "    X_train[:, 19:] = sc.fit_transform(X_train[:, 19:])\n",
    "    X_test[:, 19:] = sc.transform(X_test[:, 19:])\n",
    "\n",
    "    ## Handling Class Imbalance \n",
    "    # Apply SMOTE - SMOTE generates synthetic samples for the minority class to balance the dataset:\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    classifier = RandomForestClassifier(random_state=0, **best_params)\n",
    "    classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics for this fold\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    precision_scores.append(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "    recall_scores.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# Calculate the average evaluation metrics over all folds\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "average_precision = np.mean(precision_scores)\n",
    "average_recall = np.mean(recall_scores)\n",
    "average_f1 = np.mean(f1_scores)\n",
    "\n",
    "# Append results for this time interval\n",
    "results.append([ '5 min', round(average_accuracy, 3), round(std_accuracy, 3), round(average_precision, 3), round(average_recall, 3), round(average_f1, 3)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gender', 'age_gen', 'day', 'timeofday', 'first_outcome', 'first_wager',\n",
      "       'first_p/b', 'last_outcome', 'last_wager', 'last_p/b', 'beginning_amt',\n",
      "       'ending_amt', 'ending_balance', 'ave_slotdenom', 'std_slotdenom',\n",
      "       'min_slotdenom', 'max_slotdenom', 'ave_theo_payback',\n",
      "       'min_theo_payback', 'max_theo_payback', 'ave_wageramt', 'std_wageramt',\n",
      "       'min_wager', 'max_wager', 'ave_p/b', 'std_p/b', 'max_p/b', 'max_profit',\n",
      "       'depletion_slope', '#inc_slotdenom', '#dec_slotdenom', '#inc_maxbet',\n",
      "       '#dec_maxbet', '#W', '#L', '#NH', '#D', 'w/min', 'l/min', '#2ws',\n",
      "       '2ws_profit', '2ws_wgramt', '2ws/min', '#3ws', '3ws_profit',\n",
      "       '3ws_wgramt', '3ws/min', '#4ws', '4ws_profit', '4ws_wgramt', '4ws/min',\n",
      "       'w/g', 'l/g', 'nh/g', 'd/g', 'ave_time_per_gamble',\n",
      "       'min_time_per_gamble', 'max_time_per_gamble', 'total_gambles',\n",
      "       'machines_changes', 'unique_machines', 'ave_time_per_machine',\n",
      "       'classification'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data_10min = cf.load_and_preprocess_datasets_min_ntop(months, data_path, '10min', filter)\n",
    "\n",
    "# Concat all dataframes on data_1min\n",
    "dataset = pd.concat(data_10min)\n",
    "\n",
    "print(dataset.columns)\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # # Encode age_generartion, first_outoce, last_outcome, time of day columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 3, 4, 7])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Initialize stratified k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    # Scale all columns except the encoded ones\n",
    "    X_train[:, 19:] = sc.fit_transform(X_train[:, 19:])\n",
    "    X_test[:, 19:] = sc.transform(X_test[:, 19:])\n",
    "\n",
    "    ## Handling Class Imbalance \n",
    "    # Apply SMOTE - SMOTE generates synthetic samples for the minority class to balance the dataset:\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    classifier = RandomForestClassifier(random_state=0, **best_params)\n",
    "    classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics for this fold\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    precision_scores.append(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "    recall_scores.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# Calculate the average evaluation metrics over all folds\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "average_precision = np.mean(precision_scores)\n",
    "average_recall = np.mean(recall_scores)\n",
    "average_f1 = np.mean(f1_scores)\n",
    "\n",
    "# Append results for this time interval\n",
    "results.append([ '10 min', round(average_accuracy, 3), round(std_accuracy, 3), round(average_precision, 3), round(average_recall, 3), round(average_f1, 3)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gender', 'age_gen', 'day', 'timeofday', 'first_outcome', 'first_wager',\n",
      "       'first_p/b', 'last_outcome', 'last_wager', 'last_p/b', 'beginning_amt',\n",
      "       'ending_amt', 'ending_balance', 'ave_slotdenom', 'std_slotdenom',\n",
      "       'min_slotdenom', 'max_slotdenom', 'ave_theo_payback',\n",
      "       'min_theo_payback', 'max_theo_payback', 'ave_wageramt', 'std_wageramt',\n",
      "       'min_wager', 'max_wager', 'ave_p/b', 'std_p/b', 'max_p/b', 'max_profit',\n",
      "       'depletion_slope', '#inc_slotdenom', '#dec_slotdenom', '#inc_maxbet',\n",
      "       '#dec_maxbet', '#W', '#L', '#NH', '#D', 'w/min', 'l/min', '#2ws',\n",
      "       '2ws_profit', '2ws_wgramt', '2ws/min', '#3ws', '3ws_profit',\n",
      "       '3ws_wgramt', '3ws/min', '#4ws', '4ws_profit', '4ws_wgramt', '4ws/min',\n",
      "       'w/g', 'l/g', 'nh/g', 'd/g', 'ave_time_per_gamble',\n",
      "       'min_time_per_gamble', 'max_time_per_gamble', 'total_gambles',\n",
      "       'machines_changes', 'unique_machines', 'ave_time_per_machine',\n",
      "       'classification'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data_15min = cf.load_and_preprocess_datasets_min_ntop(months, data_path, '15min', filter)\n",
    "\n",
    "# Concat all dataframes on data_1min\n",
    "dataset = pd.concat(data_15min)\n",
    "\n",
    "print(dataset.columns)\n",
    "\n",
    "# # Seperate dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Econde gender column (Binary)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Binary Encode gender\n",
    "X[:, 0] = le.fit_transform(X[:, 0])\n",
    "\n",
    "# # # Encode age_generartion, first_outoce, last_outcome, time of day columns\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 3, 4, 7])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Initialize stratified k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# Lists to store evaluation metrics for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    # Scale all columns except the encoded ones\n",
    "    X_train[:, 19:] = sc.fit_transform(X_train[:, 19:])\n",
    "    X_test[:, 19:] = sc.transform(X_test[:, 19:])\n",
    "\n",
    "    ## Handling Class Imbalance \n",
    "    # Apply SMOTE - SMOTE generates synthetic samples for the minority class to balance the dataset:\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    classifier = RandomForestClassifier(random_state=0, **best_params)\n",
    "    classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics for this fold\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    precision_scores.append(precision_score(y_test, y_pred, average='macro', zero_division=1))\n",
    "    recall_scores.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# Calculate the average evaluation metrics over all folds\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "average_precision = np.mean(precision_scores)\n",
    "average_recall = np.mean(recall_scores)\n",
    "average_f1 = np.mean(f1_scores)\n",
    "\n",
    "# Append results for this time interval\n",
    "results.append([ '15 min', round(average_accuracy, 3), round(std_accuracy, 3), round(average_precision, 3), round(average_recall, 3), round(average_f1, 3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "  Time &  Mean Accuracy &  Acc. Std &   Mean Precision &  Mean Recall &  Mean F1 Score \\\\\n",
      "\\midrule\n",
      " 1 min &          0.620 &     0.006 &            0.548 &        0.626 &          0.499 \\\\\n",
      " 5 min &          0.657 &     0.003 &            0.563 &        0.661 &          0.529 \\\\\n",
      "10 min &          0.684 &     0.005 &            0.575 &        0.687 &          0.552 \\\\\n",
      "15 min &          0.708 &     0.006 &            0.583 &        0.701 &          0.570 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/1skwx2kd29s4fxnxx7tt9r6w0000gn/T/ipykernel_34689/451716388.py:9: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = results_df.to_latex(index=False, escape=False)\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame for the results\n",
    "columns = ['Time', 'Mean Accuracy', 'Acc. Std', ' Mean Precision', 'Mean Recall', 'Mean F1 Score']\n",
    "results_df = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "# Print the results as a table\n",
    "# print(results_df)\n",
    "\n",
    "# Print the results as a LaTeX table\n",
    "latex_table = results_df.to_latex(index=False, escape=False)\n",
    "print(latex_table)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
