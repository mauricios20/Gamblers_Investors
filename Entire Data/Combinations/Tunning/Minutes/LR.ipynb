{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import random\n",
    "import counting_fns as cf\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "# List of all the months\n",
    "months = ['2_June', '3_July', '4_August', '5_September', '6_October']\n",
    "\n",
    "# Define the path to the data directory and columns to keep\n",
    "data_path = \"/Users/mau/Library/CloudStorage/Dropbox/Mac/Documents/Dissertation/Chapter 2/Entire_Data/By month\"\n",
    "\n",
    "# Filter Columns\n",
    "filter = ['session_time', 'gender', 'age_gen', 'day', 'timeofday', 'first_outcome',\n",
    "        'first_wager','first_p/b', 'last_outcome', 'last_wager', 'last_p/b',\n",
    "        'beginning_amt', 'ending_amt', 'ending_balance', 'ave_slotdenom', \n",
    "        'std_slotdenom', 'min_slotdenom', 'max_slotdenom', 'ave_theo_payback',\n",
    "        'min_theo_payback', 'max_theo_payback', 'ave_wageramt', 'std_wageramt',\n",
    "        'min_wager', 'max_wager', 'ave_p/b', 'std_p/b', 'max_p/b', 'max_profit', 'depletion_slope', \n",
    "        '#inc_slotdenom', '#dec_slotdenom', '#inc_maxbet', '#dec_maxbet', '#W', '#L', '#NH', '#D',\n",
    "        'w/min', 'l/min', '#2ws', '2ws_profit', '2ws_wgramt','2ws/min', \n",
    "        '#3ws', '3ws_profit', '3ws_wgramt', '3ws/min', '#4ws', '4ws_profit', '4ws_wgramt', '4ws/min', \n",
    "        'w/g', 'l/g', 'nh/g', 'd/g', 'ave_time_per_gamble', \n",
    "        'min_time_per_gamble', 'max_time_per_gamble', 'total_gambles',\n",
    "        'machines_changes', 'unique_machines', 'ave_time_per_machine', 'classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "Best_params_oct = {'C': 10, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga'}\n",
    "Best_params_sep = {'C': 10, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear'}\n",
    "Best_params_aug = {'C': 1, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga'}\n",
    "Best_params_jul = {'C': 10, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear'}\n",
    "Best_params_june =  {'C': 10, 'max_iter': 300, 'penalty': 'l1', 'solver': 'liblinear'}\n",
    "\n",
    "# Best_params overall\n",
    "best_params = {'C': 10, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "  Time &  Accuracy &  Precision &  Recall &  F1 Score \\\\\n",
      "\\midrule\n",
      " 1 min &     0.600 &      0.516 &   0.540 &     0.467 \\\\\n",
      " 5 min &     0.569 &      0.539 &   0.602 &     0.471 \\\\\n",
      "10 min &     0.608 &      0.554 &   0.639 &     0.502 \\\\\n",
      "15 min &     0.662 &      0.575 &   0.685 &     0.544 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/1skwx2kd29s4fxnxx7tt9r6w0000gn/T/ipykernel_4286/2409925645.py:94: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = results_df.to_latex(index=False, escape=False)\n"
     ]
    }
   ],
   "source": [
    "# Table creation \n",
    "# Define time intervals\n",
    "time_intervals = [1, 5, 10, 15]\n",
    "\n",
    "# Initialize lists to store results\n",
    "results = []\n",
    "dataframes_features = {}\n",
    "for time_interval in time_intervals:\n",
    "    # Load dataset for the specific time interval\n",
    "    file_name = f'{time_interval}min'\n",
    "    # Load the datasets\n",
    "    datasets = cf.load_and_preprocess_datasets_min_ntop(months, data_path, file_name, filter)\n",
    "\n",
    "    # Create training and test sets\n",
    "    dt_train = pd.concat([datasets['dtf'+month[1:]] for month in months_train])\n",
    "    dt_test = pd.concat([datasets['dtf'+month[1:]] for month in months_test])\n",
    "\n",
    "    # # Seperate dependent and independent variables\n",
    "    X_train = dt_train.iloc[:, :-1].values\n",
    "    y_train = dt_train.iloc[:, -1].values\n",
    "    X_test = dt_test.iloc[:, :-1].values\n",
    "    y_test = dt_test.iloc[:, -1].values\n",
    "\n",
    "    # Econde gender column (Binary)\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    # Binary Encode gender\n",
    "    X_train[:, 0] = le.fit_transform(X_train[:, 0])\n",
    "    X_test[:, 0] = le.transform(X_test[:, 0])\n",
    "\n",
    "    # # # Encode age_generartion, first_outoce, last_outcome, time of day columns\n",
    "    ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1, 2, 3, 4, 7])], remainder='passthrough')\n",
    "    X_train = ct.fit_transform(X_train)\n",
    "    X_test = ct.transform(X_test)\n",
    "\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.fit_transform(y_test)\n",
    "\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    # Scale all columns except the encoded ones\n",
    "    X_train[:, 25:] = sc.fit_transform(X_train[:, 25:])\n",
    "    X_test[:, 25:] = sc.transform(X_test[:, 25:])\n",
    "\n",
    "    # Apply SMOTE to balance the dataset\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train_resample, y_train_resample = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Shuffle the resampled data\n",
    "    X_train_resample, y_train_resample = shuffle(X_train_resample, y_train_resample, random_state=42)\n",
    "\n",
    "    classifier = LogisticRegression(random_state = 0, **best_params)\n",
    "    classifier.fit(X_train_resample, y_train_resample)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Append results for this time interval\n",
    "    results.append([f'{time_interval} min', round(accuracy, 3), round(precision, 3), round(recall, 3), round(f1, 3)])\n",
    "\n",
    "    # drop last column\n",
    "    dataset= dt_train.drop(['classification'], axis=1)\n",
    "\n",
    "    # Get the feature names without 'remainder__' prefix\n",
    "    feature_names = cf.get_feature_names_without_prefix(ct, input_features=dataset.columns)\n",
    "\n",
    "    # Get the coefficients and feature names\n",
    "    coefficients = classifier.coef_[0]\n",
    "\n",
    "    # Create a DataFrame to display coefficients and feature names\n",
    "    coefficients_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})\n",
    "\n",
    "    # Sort the coefficients by magnitude\n",
    "    coefficients_df['Abs_Coefficient'] = np.abs(coefficients_df['Coefficient'])\n",
    "    coefficients_df = coefficients_df.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "    dataframes_features[f'coefficients_df_{time_interval}min'] = coefficients_df\n",
    "    \n",
    "\n",
    "# Create a DataFrame for the results\n",
    "columns = ['Time', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "results_df = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "# Print the results as a table\n",
    "# print(results_df)\n",
    "\n",
    "# Print the results as a LaTeX table\n",
    "latex_table = results_df.to_latex(index=False, escape=False)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 features for 1 min\n",
      "                    Feature  Coefficient  Abs_Coefficient\n",
      "2    encoder__age_gen_Gen Z    -1.426960         1.426960\n",
      "35            max_slotdenom    -1.173588         1.173588\n",
      "34            min_slotdenom     1.025136         1.025136\n",
      "37         min_theo_payback     0.973820         0.973820\n",
      "4   encoder__age_gen_Silent     0.763462         0.763462\n",
      "\n",
      "\n",
      "Top 5 features for 5 min\n",
      "                          Feature  Coefficient  Abs_Coefficient\n",
      "2          encoder__age_gen_Gen Z    -1.283728         1.283728\n",
      "4         encoder__age_gen_Silent     0.777079         0.777079\n",
      "3     encoder__age_gen_Millenials    -0.567228         0.567228\n",
      "0   encoder__age_gen_Baby Boomers     0.557004         0.557004\n",
      "37               min_theo_payback     0.448205         0.448205\n",
      "\n",
      "\n",
      "Top 5 features for 10 min\n",
      "                        Feature  Coefficient  Abs_Coefficient\n",
      "2        encoder__age_gen_Gen Z    -1.162365         1.162365\n",
      "4       encoder__age_gen_Silent     0.728987         0.728987\n",
      "36             ave_theo_payback     0.633524         0.633524\n",
      "32                ave_slotdenom    -0.627281         0.627281\n",
      "3   encoder__age_gen_Millenials    -0.560756         0.560756\n",
      "\n",
      "\n",
      "Top 5 features for 15 min\n",
      "                          Feature  Coefficient  Abs_Coefficient\n",
      "2          encoder__age_gen_Gen Z    -1.150293         1.150293\n",
      "4         encoder__age_gen_Silent     0.660880         0.660880\n",
      "3     encoder__age_gen_Millenials    -0.531085         0.531085\n",
      "0   encoder__age_gen_Baby Boomers     0.506942         0.506942\n",
      "36               ave_theo_payback     0.423733         0.423733\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Top 5 features for each time interval\n",
    "for time_interval in time_intervals:\n",
    "    print(f'Top 5 features for {time_interval} min')\n",
    "    print(dataframes_features[f'coefficients_df_{time_interval}min'].head(5))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datafranes to csv files\n",
    "for "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
